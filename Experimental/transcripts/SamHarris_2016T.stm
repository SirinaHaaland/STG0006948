SamHarris_2016T 1 SamHarris_2016T 13.51 15.06 <NA> <unk> a failure of intuition
SamHarris_2016T 1 SamHarris_2016T 15.06 24.96 <NA> that many of us suffer from it 's really a failure to detect a certain kind of danger i 'm going to describe a scenario that i think is both
SamHarris_2016T 1 SamHarris_2016T 26.42 31.68 <NA> <unk> and likely to occur <unk> and that 's not a good combination as it turns out <unk> 
SamHarris_2016T 1 SamHarris_2016T 31.58 36.96 <NA> and yet rather than be scared most of you will feel that what i 'm talking about is kind of cool i 'm going
SamHarris_2016T 1 SamHarris_2016T 36.74 46.63 <NA> to describe how the gains we make in artificial intelligence could ultimately destroy us and in fact i think it 's very difficult to see how they won 't destroy us
SamHarris_2016T 1 SamHarris_2016T 46.44 49.87 <NA> or inspire us to destroy ourselves <unk> and yet if you 're
SamHarris_2016T 1 SamHarris_2016T 51.42 53.98 <NA> <unk> find that it 's fun to think about these things
SamHarris_2016T 1 SamHarris_2016T 53.55 62.41 <NA> and that that response is part of the problem ok that response should worry you and if i were to convince you in this talk
SamHarris_2016T 1 SamHarris_2016T 62.1 68.98 <NA> that we were likely to suffer a global famine either because of climate change or some other catastrophe <unk> 
SamHarris_2016T 1 SamHarris_2016T 68.64 74.98 <NA> and that your grandchildren or their grandchildren are very likely to live like this 
SamHarris_2016T 1 SamHarris_2016T 78.82 80.36 <NA> <unk> i like this ted talk 
SamHarris_2016T 1 SamHarris_2016T 80.53 83.24 <NA> famine isn 't fun <unk> 
SamHarris_2016T 1 SamHarris_2016T 83.32 93.12 <NA> death by science fiction on the other hand is fun <unk> and one of the things that worries me most about the development of ai at this point is that we seem unable to marshal
SamHarris_2016T 1 SamHarris_2016T 92.93 97.1 <NA> an appropriate emotional response to the dangers that lie ahead
SamHarris_2016T 1 SamHarris_2016T 96.76 104.19 <NA> i am unable to marshal this response and i 'm giving this talk it 's as though we stand before two doors
SamHarris_2016T 1 SamHarris_2016T 104.81 113.22 <NA> <unk> behind door number one we stop making progress in building intelligent machines our computer hardware and software just stops getting better for some reason <unk> 
SamHarris_2016T 1 SamHarris_2016T 112.97 116.91 <NA> now take a moment to consider why this might happen i mean
SamHarris_2016T 1 SamHarris_2016T 116.6 124.68 <NA> given how valuable intelligence and automation are <unk> we will continue to improve our technology if we are at all able to 
SamHarris_2016T 1 SamHarris_2016T 124.73 126.76 <NA> what could stop us from doing this
SamHarris_2016T 1 SamHarris_2016T 130.53 132.79 <NA> a global pandemic 
SamHarris_2016T 1 SamHarris_2016T 133.89 136.06 <NA> an asteroid impact 
SamHarris_2016T 1 SamHarris_2016T 137.16 140.17 <NA> justin bieber becoming president of the united states 
SamHarris_2016T 1 SamHarris_2016T 144.18 149.29 <NA> laughter the point is something would have to destroy civilization as we know it 
SamHarris_2016T 1 SamHarris_2016T 149.34 153.68 <NA> you have to imagine how bad it would have to be
SamHarris_2016T 1 SamHarris_2016T 153.45 154.97 <NA> to prevent us from making
SamHarris_2016T 1 SamHarris_2016T 155.05 156.92 <NA> <unk> improvements in our technology
SamHarris_2016T 1 SamHarris_2016T 156.75 163.67 <NA> permanently generation after generation almost by definition this is the worst thing that 's ever happened in human history 
SamHarris_2016T 1 SamHarris_2016T 164.05 171.39 <NA> so the only alternative <unk> and this is what lies behind door number two is that we continue to improve our intelligent machines
SamHarris_2016T 1 SamHarris_2016T 171.15 179.97 <NA> year after year after year at a certain point <unk> we will build machines that are smarter than we are and once we have machines that are smarter than we are
SamHarris_2016T 1 SamHarris_2016T 179.99 182.25 <NA> <unk> they will begin to improve themselves <unk> 
SamHarris_2016T 1 SamHarris_2016T 182.24 189.9 <NA> and then we risk what the mathematician ij good called an intelligence explosion that the process could get away from us 
SamHarris_2016T 1 SamHarris_2016T 189.65 199.59 <NA> now this is often caricatured as i have here as a fear that armies of malicious robots will attack us but that isn 't the most likely scenario
SamHarris_2016T 1 SamHarris_2016T 200.4 202.99 <NA> <unk> not that our machines will become
SamHarris_2016T 1 SamHarris_2016T 202.56 206.68 <NA> spontaneously malevolent the concern is really that
SamHarris_2016T 1 SamHarris_2016T 206.51 215.08 <NA> we will build machines that are so much more competent than we are that the slightest divergence between their goals and our own could destroy us 
SamHarris_2016T 1 SamHarris_2016T 215.46 218.62 <NA> just think about how we relate to ants
SamHarris_2016T 1 SamHarris_2016T 218.19 226.54 <NA> we don 't hate them we don 't go out of our way to harm them in fact sometimes we take pains not to harm them <unk> we step over them on the sidewalk <unk> 
SamHarris_2016T 1 SamHarris_2016T 226.35 228.97 <NA> but whenever their presence
SamHarris_2016T 1 SamHarris_2016T 228.48 230 <NA> seriously conflicts
SamHarris_2016T 1 SamHarris_2016T 229.99 236.3 <NA> <unk> with one of our goals <unk> let 's say when constructing a building like this one we annihilate them without a qualm <unk> 
SamHarris_2016T 1 SamHarris_2016T 236.23 244.55 <NA> the concern is that we will one day build machines that whether they 're conscious or not could treat us with similar disregard 
SamHarris_2016T 1 SamHarris_2016T 245.32 252.39 <NA> now i suspect this seems far fetched to many of you i bet there are those of you who doubt that
SamHarris_2016T 1 SamHarris_2016T 255.23 262.59 <NA> much less inevitable but then you must find something wrong with one of the following assumptions <unk> and there are only three of them
SamHarris_2016T 1 SamHarris_2016T 262.85 267.37 <NA> <unk> intelligence is a matter of information processing
SamHarris_2016T 1 SamHarris_2016T 267.2 269.04 <NA> in physical systems
SamHarris_2016T 1 SamHarris_2016T 268.91 274.72 <NA> actually this is a little bit more than an assumption we have already built narrow intelligence into our
SamHarris_2016T 1 SamHarris_2016T 275.4 283.33 <NA> <unk> and many of these machines perform at a level of of superhuman intelligence already <unk> and we know that mere matter
SamHarris_2016T 1 SamHarris_2016T 282.93 292.78 <NA> can give rise to what is called general intelligence an ability to think flexibly across multiple domains <unk> because our brains have managed it right i
SamHarris_2016T 1 SamHarris_2016T 294.36 299.44 <NA> there 's just atoms in here and as long as we continue to
SamHarris_2016T 1 SamHarris_2016T 299.25 304.97 <NA> build systems of atoms that display more and more intelligent behavior <unk> we will eventually
SamHarris_2016T 1 SamHarris_2016T 305.28 308.21 <NA> unless we are interrupted we will eventually
SamHarris_2016T 1 SamHarris_2016T 307.75 315.05 <NA> build general intelligence into our machines <unk> it 's crucial to realize that that the rate of progress doesn 't matter
SamHarris_2016T 1 SamHarris_2016T 314.59 321.9 <NA> because any progress is enough to get us into the end zone we don 't need moore 's law to continue we don 't need exponential progress 
SamHarris_2016T 1 SamHarris_2016T 321.9 323.93 <NA> we just need to keep going <unk> 
SamHarris_2016T 1 SamHarris_2016T 325.03 329.94 <NA> the second assumption is that we will keep going <unk> we will continue
SamHarris_2016T 1 SamHarris_2016T 329.87 334.23 <NA> <unk> to improve our intelligent machines <unk> and
SamHarris_2016T 1 SamHarris_2016T 334.19 340.77 <NA> given the value of intelligence i mean intelligence is either the source of everything we value
SamHarris_2016T 1 SamHarris_2016T 340.43 345.79 <NA> or we need it to safeguard everything we value it is our most valuable resource <unk> 
SamHarris_2016T 1 SamHarris_2016T 345.79 354.13 <NA> so we want to do this <unk> we have problems that we desperately need to solve <unk> we want to cure diseases like alzheimer 's and cancer
SamHarris_2016T 1 SamHarris_2016T 355.05 364.54 <NA> <unk> want to understand economic systems we want to improve our climate science <unk> so we will do this if we can the train is already out of the station and there 's no brake to pull 
SamHarris_2016T 1 SamHarris_2016T 365.4 368.75 <NA> finally <unk> we don 't stand
SamHarris_2016T 1 SamHarris_2016T 368.33 371.26 <NA> on a peak of intelligence 
SamHarris_2016T 1 SamHarris_2016T 370.89 379.91 <NA> or anywhere near it likely <unk> and this really is the crucial insight this is what makes our situation so precarious <unk> and this is what what makes our intuitions
SamHarris_2016T 1 SamHarris_2016T 379.84 380.89 <NA> <unk> about risk
SamHarris_2016T 1 SamHarris_2016T 380.67 385.94 <NA> so unreliable now just consider the smartest person who has ever lived 
SamHarris_2016T 1 SamHarris_2016T 386.2 389.88 <NA> on almost everyone 's shortlist here is john von neumann i
SamHarris_2016T 1 SamHarris_2016T 389.88 397.46 <NA> mean the impression that von neumann made on the people around him <unk> and this included the greatest mathematicians and physicists of his time 
SamHarris_2016T 1 SamHarris_2016T 397.03 398.18 <NA> is fairly <unk>
SamHarris_2016T 1 SamHarris_2016T 400.16 406.29 <NA> <unk> if only half the stories about him are half true there 's no question he 's one of the smartest people who has ever lived <unk> 
SamHarris_2016T 1 SamHarris_2016T 406.31 411.99 <NA> so consider the spectrum of intelligence here we have john von neumann 
SamHarris_2016T 1 SamHarris_2016T 413.12 417.57 <NA> and then we have you and me <unk> and then we have a chicken 
SamHarris_2016T 1 SamHarris_2016T 418.88 424.3 <NA> sorry a chicken there 's no reason for me to make this talk more depressing than it needs to
SamHarris_2016T 1 SamHarris_2016T 430.14 435.43 <NA> <unk> however that the spectrum of intelligence extends much further than we currently conceive <unk> 
SamHarris_2016T 1 SamHarris_2016T 435.42 438.94 <NA> and if we build machines that are more intelligent than we are 
SamHarris_2016T 1 SamHarris_2016T 438.63 446.14 <NA> they will very likely explore this spectrum in ways that we can 't imagine and exceed us in ways that we can 't imagine and it
SamHarris_2016T 1 SamHarris_2016T 446.67 450.26 <NA> 's important to recognize that this is true by virtue of speed
SamHarris_2016T 1 SamHarris_2016T 456.4 466.32 <NA> <unk> that was no smarter than your average team of researchers at stanford or mit <unk> well <unk> electronic circuits function about a million times faster than biochemical ones
SamHarris_2016T 1 SamHarris_2016T 466.11 471.26 <NA> so this machine should think about a million times faster than the minds that built it 
SamHarris_2016T 1 SamHarris_2016T 471.01 479.97 <NA> so you set it running for a week <unk> and it will perform twenty thousand years of human level intellectual work week after week after week
SamHarris_2016T 1 SamHarris_2016T 479.81 487.71 <NA> <unk> week how could we even understand much less constrain a mind making this sort of progress
SamHarris_2016T 1 SamHarris_2016T 488.63 491.19 <NA> the other thing that 's worrying frankly is <unk>
SamHarris_2016T 1 SamHarris_2016T 493.52 500.16 <NA> that imagine the best case scenario <unk> so imagine we we hit upon a design of superintelligent ai
SamHarris_2016T 1 SamHarris_2016T 499.67 504.22 <NA> that has no safety concerns we have the perfect design the first time around
SamHarris_2016T 1 SamHarris_2016T 504.9 513.58 <NA> <unk> it 's as though we 've been handed an oracle that behaves exactly as intended <unk> well <unk> this machine would be the perfect <unk> labor saving device <unk> 
SamHarris_2016T 1 SamHarris_2016T 513.24 521.83 <NA> it can design the machine that can build the machine that can do any physical work <unk> powered by sunlight more or less for the cost of raw materials
SamHarris_2016T 1 SamHarris_2016T 521.82 528.52 <NA> <unk> so we 're talking about the end of human drudgery we 're also talking about the end of most intellectual work <unk> 
SamHarris_2016T 1 SamHarris_2016T 528.75 529.97 <NA> so what would apes
SamHarris_2016T 1 SamHarris_2016T 529.9 534.38 <NA> <unk> like ourselves do in this circumstance <unk> well we 'd be free to
SamHarris_2016T 1 SamHarris_2016T 533.98 536.84 <NA> play frisbee and give each other massages
SamHarris_2016T 1 SamHarris_2016T 537.25 543.02 <NA> <unk> add some lsd and some questionable wardrobe choices and the whole world could be like burning man 
SamHarris_2016T 1 SamHarris_2016T 545.89 548.78 <NA> now that might sound pretty good <unk> 
SamHarris_2016T 1 SamHarris_2016T 548.8 554.97 <NA> but ask yourself what would happen under our current economic and political order <unk> it seems
SamHarris_2016T 1 SamHarris_2016T 554.93 558.96 <NA> <unk> likely that we would witness a level of wealth inequality
SamHarris_2016T 1 SamHarris_2016T 558.89 567.06 <NA> and unemployment that we have never seen before absent a willingness to immediately put this new wealth to the service of all humanity 
SamHarris_2016T 1 SamHarris_2016T 567.5 573.63 <NA> a few <unk> trillionaires could grace the covers of our business magazines while the rest of the world would be free to starve <unk> 
SamHarris_2016T 1 SamHarris_2016T 573.86 579.91 <NA> and what would the russians or the chinese do if they heard that some company in silicon valley was about to
SamHarris_2016T 1 SamHarris_2016T 579.87 589.27 <NA> <unk> deploy a superintelligent ai this machine would be capable of waging war <unk> whether terrestrial or cyber with unprecedented power
SamHarris_2016T 1 SamHarris_2016T 589.74 595.09 <NA> <unk> this is a winner take all scenario to be six months ahead of the competition here
SamHarris_2016T 1 SamHarris_2016T 594.66 599.08 <NA> is to be five hundred thousand years ahead at a minimum
SamHarris_2016T 1 SamHarris_2016T 599.1 600.11 <NA> so it seems
SamHarris_2016T 1 SamHarris_2016T 600.58 602.69 <NA> <unk> even mere rumors
SamHarris_2016T 1 SamHarris_2016T 602.29 611.84 <NA> of this kind of breakthrough could cause our species to go berserk now one of the most frightening things in my view at this moment 
SamHarris_2016T 1 SamHarris_2016T 611.92 614.49 <NA> are the kinds of things that
SamHarris_2016T 1 SamHarris_2016T 614.33 616.7 <NA> ai researchers say
SamHarris_2016T 1 SamHarris_2016T 616.21 618.56 <NA> when they want to be reassuring <unk> 
SamHarris_2016T 1 SamHarris_2016T 618.52 627.53 <NA> and the most common reason we 're told not to worry is time this is all a long way off don 't you know this is probably fifty or one hundred years away 
SamHarris_2016T 1 SamHarris_2016T 627.25 629.97 <NA> one researcher has said worrying about ai safety
SamHarris_2016T 1 SamHarris_2016T 630.28 638.13 <NA> is like worrying about overpopulation on mars this is the silicon valley version of don 't worry your pretty little head about it 
SamHarris_2016T 1 SamHarris_2016T 638.81 642.36 <NA> laughter no one seems to notice that
SamHarris_2016T 1 SamHarris_2016T 642.08 646.14 <NA> referencing the time horizon is a total non sequitur
SamHarris_2016T 1 SamHarris_2016T 646.1 654.43 <NA> <unk> if intelligence is just a matter of information processing <unk> and we continue to improve our machines <unk> we will produce some form of
SamHarris_2016T 1 SamHarris_2016T 654.71 662.65 <NA> superintelligence and we have no idea how long it will take us to create the conditions to do that safely let
SamHarris_2016T 1 SamHarris_2016T 663.75 667.57 <NA> me say that again <unk> we have no idea
SamHarris_2016T 1 SamHarris_2016T 667.11 672.07 <NA> how long it will take us to create the conditions to do that safely <unk> 
SamHarris_2016T 1 SamHarris_2016T 672.45 679.79 <NA> and if you haven 't noticed <unk> fifty years is not what it used to be this is fifty years in months <unk> this is how long we 've had the
SamHarris_2016T 1 SamHarris_2016T 680.98 684.2 <NA> this is how long the simpsons has been on television <unk> 
SamHarris_2016T 1 SamHarris_2016T 684.28 690.8 <NA> fifty years is not that much time to meet one of the greatest challenges our species will ever face 
SamHarris_2016T 1 SamHarris_2016T 691.18 698.25 <NA> once again <unk> we seem to be failing to have an appropriate emotional response to what we have every reason to believe is coming
SamHarris_2016T 1 SamHarris_2016T 698.25 701.39 <NA> the computer scientist stuart russell
SamHarris_2016T 1 SamHarris_2016T 700.9 704.82 <NA> has a nice analogy here he said imagine that we received a message
SamHarris_2016T 1 SamHarris_2016T 704.8 708.6 <NA> from an alien civilization which read 
SamHarris_2016T 1 SamHarris_2016T 708.56 714.99 <NA> people of earth <unk> we will arrive on your planet in fifty years get ready 
SamHarris_2016T 1 SamHarris_2016T 714.92 722.97 <NA> and now we 're just counting down the months until the mothership lands <unk> we would feel a little more urgency than we do
SamHarris_2016T 1 SamHarris_2016T 723.53 725.02 <NA> <unk> another
SamHarris_2016T 1 SamHarris_2016T 725 726.38 <NA> <unk> reason we 're told not to worry
SamHarris_2016T 1 SamHarris_2016T 726.2 733.95 <NA> is that these machines can 't help but share our values because they will be literally extensions of ourselves they 'll be grafted onto our brains 
SamHarris_2016T 1 SamHarris_2016T 733.96 736.39 <NA> and we 'll essentially become their limbic systems 
SamHarris_2016T 1 SamHarris_2016T 736.65 741.7 <NA> now take a moment to consider that the safest and only prudent path forward 
SamHarris_2016T 1 SamHarris_2016T 741.3 746.44 <NA> recommended is to implant this technology directly into our brains 
SamHarris_2016T 1 SamHarris_2016T 746.13 754.97 <NA> now this may in fact be the safest and only prudent path forward but usually one 's safety concerns about a technology have to be pretty much worked out before you
SamHarris_2016T 1 SamHarris_2016T 754.93 760.67 <NA> <unk> stick it inside your head the deeper problem is that
SamHarris_2016T 1 SamHarris_2016T 760.57 764.15 <NA> building <unk> superintelligent ai on its own
SamHarris_2016T 1 SamHarris_2016T 763.69 772.43 <NA> seems likely to be easier than building superintelligent ai and having the completed neuroscience that allows us to seamlessly integrate our minds with it 
SamHarris_2016T 1 SamHarris_2016T 772.36 776.01 <NA> and given that the companies and governments doing this work
SamHarris_2016T 1 SamHarris_2016T 775.77 778.83 <NA> are likely to perceive themselves as being in a race against all others
SamHarris_2016T 1 SamHarris_2016T 779.9 789.75 <NA> <unk> that to win this race is to win the world provided you don 't destroy it in the next moment then it seems likely that whatever is easier to do will get done first 
SamHarris_2016T 1 SamHarris_2016T 790.07 798.28 <NA> now unfortunately i don 't have a solution to this problem apart from recommending that more of us think about it i think we need something like a manhattan project
SamHarris_2016T 1 SamHarris_2016T 798.07 800.02 <NA> on the topic of artificial intelligence
SamHarris_2016T 1 SamHarris_2016T 800.49 806.4 <NA> <unk> not to build it because i think we 'll inevitably do that but to to understand how to avoid an arms race
SamHarris_2016T 1 SamHarris_2016T 806.18 814.27 <NA> and to build it in a way that is aligned with our interests when you 're talking about superintelligent ai that can make changes to itself 
SamHarris_2016T 1 SamHarris_2016T 814.11 824.71 <NA> it seems seems that we only have one chance to get the initial conditions right <unk> and even then we will will need to absorb the economic and political consequences of getting them right <unk> 
SamHarris_2016T 1 SamHarris_2016T 825.3 827.62 <NA> but the moment we admit
SamHarris_2016T 1 SamHarris_2016T 827.37 829.97 <NA> that information processing is
SamHarris_2016T 1 SamHarris_2016T 830.19 835.79 <NA> the source of intelligence that some appropriate computational system is what
SamHarris_2016T 1 SamHarris_2016T 835.57 842.54 <NA> the basis of intelligence is <unk> and we admit that we will improve these systems continuously <unk> 
SamHarris_2016T 1 SamHarris_2016T 842.83 847.77 <NA> and we admit that the horizon of cognition very likely far exceeds
SamHarris_2016T 1 SamHarris_2016T 847.58 853.89 <NA> what we currently know then we have to admit that we are in the process of building some sort of god
SamHarris_2016T 1 SamHarris_2016T 855.41 860.83 <NA> <unk> now would be a good time to make sure it 's a god we can live with thank you very much
