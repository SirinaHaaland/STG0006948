AbeDavis_2015 1 AbeDavis_2015 13.33 17.12 <NA> <unk> most of us think of motion as a very visual thing if
AbeDavis_2015 1 AbeDavis_2015 17.47 25.2 <NA> i walk across this stage or gesture with my hands while i speak that motion is something that you can see
AbeDavis_2015 1 AbeDavis_2015 26.36 31.53 <NA> <unk> but there 's a world of important motion that 's too subtle for the human eye <unk> 
AbeDavis_2015 1 AbeDavis_2015 31.37 39.45 <NA> and over the past few years we 've started to find that cameras can often see this motion even when humans can 't 
AbeDavis_2015 1 AbeDavis_2015 39.83 42.03 <NA> so let me show you what i mean 
AbeDavis_2015 1 AbeDavis_2015 41.99 45.81 <NA> on the left here you see video of a person 's wrist <unk> 
AbeDavis_2015 1 AbeDavis_2015 45.65 54.88 <NA> and on the right you see video of a sleeping infant but if i didn 't tell you that these were videos you might assume that you were looking at two regular
AbeDavis_2015 1 AbeDavis_2015 54.84 61.54 <NA> <unk> images because in both cases these videos appear to be almost completely still 
AbeDavis_2015 1 AbeDavis_2015 61.65 65.59 <NA> but there 's actually a lot of subtle motion going on here <unk> 
AbeDavis_2015 1 AbeDavis_2015 65.34 72.82 <NA> and if you were to touch the wrist on the left you would feel a pulse <unk> and if you were to hold the infant on the right 
AbeDavis_2015 1 AbeDavis_2015 72.33 76.87 <NA> you would feel the rise and fall of her chest as she took each breath 
AbeDavis_2015 1 AbeDavis_2015 77.19 79.64 <NA> and these motions carry a lot of
AbeDavis_2015 1 AbeDavis_2015 79.6 84.17 <NA> <unk> significance <unk> but they 're usually too subtle for us to see <unk> 
AbeDavis_2015 1 AbeDavis_2015 83.95 90.17 <NA> so instead we have to observe them through direct contact through touch <unk> 
AbeDavis_2015 1 AbeDavis_2015 90.49 96.59 <NA> but a few years ago <unk> my colleagues at mit developed what they call a motion microscope <unk> 
AbeDavis_2015 1 AbeDavis_2015 96.31 100.92 <NA> which is software that finds these subtle motions in video
AbeDavis_2015 1 AbeDavis_2015 100.68 104.4 <NA> and amplifies them so that they become large enough for us to see
AbeDavis_2015 1 AbeDavis_2015 105.32 108.39 <NA> <unk> and so if we use their software on the left video <unk> 
AbeDavis_2015 1 AbeDavis_2015 108.56 116.22 <NA> it lets us see the pulse in this wrist <unk> and if we were to count that pulse we could even figure out this person 's heart rate <unk> 
AbeDavis_2015 1 AbeDavis_2015 116.54 124.66 <NA> and if we used the same software on the right video <unk> it lets us see each breath that this infant takes <unk> and we can use this as a
AbeDavis_2015 1 AbeDavis_2015 126.12 131.63 <NA> <unk> to monitor her breathing <unk> and so this technology is really powerful
AbeDavis_2015 1 AbeDavis_2015 131.42 136.1 <NA> because it takes these phenomena that we normally have to experience through touch
AbeDavis_2015 1 AbeDavis_2015 135.89 139.78 <NA> and it lets us capture them visually and non invasively 
AbeDavis_2015 1 AbeDavis_2015 140.37 148.42 <NA> so a couple years ago <unk> i started working with the folks that created that software <unk> and we decided to pursue a crazy idea <unk> 
AbeDavis_2015 1 AbeDavis_2015 148.11 150.08 <NA> we thought it 's cool
AbeDavis_2015 1 AbeDavis_2015 150.04 158.24 <NA> <unk> that we can use software to visualize tiny motions like this and you can almost think of it as a way to extend our sense of touch <unk> 
AbeDavis_2015 1 AbeDavis_2015 158.71 163.31 <NA> but what if we could do the same thing with our ability to hear 
AbeDavis_2015 1 AbeDavis_2015 163.81 168.74 <NA> what if we could use video to capture the vibrations of sound <unk> 
AbeDavis_2015 1 AbeDavis_2015 168.82 175.49 <NA> which are just another kind of motion and turn everything that we see into a microphone now 
AbeDavis_2015 1 AbeDavis_2015 175.81 179.97 <NA> this is a bit of a strange idea <unk> so let me try to put it in perspective for
AbeDavis_2015 1 AbeDavis_2015 181.04 188.07 <NA> traditional microphones work by converting the motion of an internal diaphragm into an electrical signal <unk> 
AbeDavis_2015 1 AbeDavis_2015 188.15 192.6 <NA> and that diaphragm is designed to move readily with sound
AbeDavis_2015 1 AbeDavis_2015 192.14 199.87 <NA> so that its motion can be recorded and interpreted as audio <unk> but sound causes all objects to
AbeDavis_2015 1 AbeDavis_2015 201.09 210.25 <NA> <unk> those vibrations are just usually too subtle and too fast for us to see so what if we record them with a high speed camera
AbeDavis_2015 1 AbeDavis_2015 210 215.89 <NA> and then use software to extract tiny motions from our high speed video 
AbeDavis_2015 1 AbeDavis_2015 215.61 220.69 <NA> and analyze those motions to figure out what sounds created them 
AbeDavis_2015 1 AbeDavis_2015 221.22 224.84 <NA> this would let us turn visible objects into
AbeDavis_2015 1 AbeDavis_2015 225 227.57 <NA> <unk> visual microphones from a distance
AbeDavis_2015 1 AbeDavis_2015 228.67 235.77 <NA> and so we tried this out and here 's one of our experiments where we took this potted plant that you see on the right
AbeDavis_2015 1 AbeDavis_2015 235.77 240.93 <NA> and we filmed it with a high speed camera while a nearby loudspeaker played this sound
AbeDavis_2015 1 AbeDavis_2015 255.11 258.18 <NA> <unk> it at thousands of frames per second <unk> 
AbeDavis_2015 1 AbeDavis_2015 257.81 265.92 <NA> but even if you look very closely all you 'll see are some leaves that are pretty much just sitting there doing nothing <unk> 
AbeDavis_2015 1 AbeDavis_2015 265.82 271.93 <NA> because our sound only moved those leaves by about a micrometer that 's one
AbeDavis_2015 1 AbeDavis_2015 273.1 279.94 <NA> of a centimeter <unk> which spans somewhere between a hundredth and a thousandth of a pixel in
AbeDavis_2015 1 AbeDavis_2015 279.9 288.52 <NA> <unk> this image <unk> so you can squint all you want <unk> but motion that small is pretty much perceptually invisible 
AbeDavis_2015 1 AbeDavis_2015 289.05 296.14 <NA> but it turns out that something can be perceptually invisible and still be numerically significant <unk> 
AbeDavis_2015 1 AbeDavis_2015 295.98 299.99 <NA> because with the right algorithms we can take this silent
AbeDavis_2015 1 AbeDavis_2015 322.18 329.97 <NA> <unk> how is this possible how can we get so much information out of so little motion well let 's say
AbeDavis_2015 1 AbeDavis_2015 330.1 338.31 <NA> that those leaves move by just a single micrometer <unk> and let 's say that that shifts our image by just a thousandth of a pixel 
AbeDavis_2015 1 AbeDavis_2015 338.81 346.68 <NA> that may not seem like much <unk> but a single frame of video may have hundreds of thousands of pixels in it <unk> 
AbeDavis_2015 1 AbeDavis_2015 346.55 354.97 <NA> and so if we combine all of the tiny motions that we see from across that entire image <unk> then suddenly a thousandth of a pixel
AbeDavis_2015 1 AbeDavis_2015 354.66 362.32 <NA> <unk> pixel can start to add up to something pretty significant on a personal note we were pretty psyched when we figured this out 
AbeDavis_2015 1 AbeDavis_2015 363.75 365.74 <NA> laughter but
AbeDavis_2015 1 AbeDavis_2015 365.55 371.17 <NA> even with the right algorithm <unk> we were still missing a pretty important piece of the puzzle 
AbeDavis_2015 1 AbeDavis_2015 371.25 379.22 <NA> you see there are a lot of factors that affect when and how well this technique will work <unk> there 's the object and how far away it
AbeDavis_2015 1 AbeDavis_2015 379.81 387.11 <NA> there 's the camera and the lens that you use how much light is shining on the object and how loud your sound is 
AbeDavis_2015 1 AbeDavis_2015 387.67 390.92 <NA> and even with the right algorithm <unk> 
AbeDavis_2015 1 AbeDavis_2015 390.76 401.12 <NA> we had to be very careful with our early experiments <unk> because if we got any of these factors wrong there was no way to tell what the problem was we would just get noise back 
AbeDavis_2015 1 AbeDavis_2015 401.44 404.58 <NA> and so a lot of our early experiments looked like this
AbeDavis_2015 1 AbeDavis_2015 405.17 407.43 <NA> <unk> and so here i am <unk> 
AbeDavis_2015 1 AbeDavis_2015 407.36 416.67 <NA> and on the bottom left you can kind of see our high speed camera <unk> which is pointed at a bag of chips <unk> and the whole thing is lit by these bright lamps <unk> 
AbeDavis_2015 1 AbeDavis_2015 416.57 422.77 <NA> and like i said <unk> we had to be very careful in these early experiments <unk> so this is how it went down
AbeDavis_2015 1 AbeDavis_2015 437.37 440.23 <NA> <unk> so this experiment looks completely ridiculous 
AbeDavis_2015 1 AbeDavis_2015 441.72 449.81 <NA> i mean i 'm screaming at a bag of chips and we 're blasting it with so much light we literally melted the first bag we tried this
AbeDavis_2015 1 AbeDavis_2015 469.21 477.44 <NA> <unk> and this was really significant <unk> because it was the first time we recovered intelligible human speech from silent video of an object 
AbeDavis_2015 1 AbeDavis_2015 477.37 479.94 <NA> and so it gave us this point of reference
AbeDavis_2015 1 AbeDavis_2015 480.01 483.93 <NA> <unk> and gradually we could start to modify the experiment 
AbeDavis_2015 1 AbeDavis_2015 483.65 490.83 <NA> using different objects or moving the object further away <unk> using less light or quieter sounds 
AbeDavis_2015 1 AbeDavis_2015 491.42 497.97 <NA> and we analyzed all of these experiments until we really understood the limits of our technique <unk> 
AbeDavis_2015 1 AbeDavis_2015 497.66 502.2 <NA> because once we understood those limits we could figure out how to push them 
AbeDavis_2015 1 AbeDavis_2015 502.1 504.58 <NA> and that led to experiments like this one
AbeDavis_2015 1 AbeDavis_2015 505.08 508.61 <NA> where again i 'm going to speak to a bag of chips <unk> 
AbeDavis_2015 1 AbeDavis_2015 508.61 516.19 <NA> but this time we 've moved our camera about fifteen feet away outside behind a soundproof window <unk> 
AbeDavis_2015 1 AbeDavis_2015 515.7 519.43 <NA> and the whole thing is lit by only natural sunlight
AbeDavis_2015 1 AbeDavis_2015 520.11 524.9 <NA> and so here 's the video that we captured and this is what
AbeDavis_2015 1 AbeDavis_2015 539.65 545.04 <NA> <unk> and here 's what we were able to recover from our silent video captured outside behind that window
AbeDavis_2015 1 AbeDavis_2015 562.46 567.96 <NA> <unk> there are other ways that we can push these limits as well <unk> so here 's a quieter experiment
AbeDavis_2015 1 AbeDavis_2015 567.56 576.21 <NA> where we filmed some earphones plugged into a laptop computer <unk> and in this case our goal was to recover the music that was playing on that laptop
AbeDavis_2015 1 AbeDavis_2015 575.72 579.94 <NA> from just silent video of these two little plastic earphones
AbeDavis_2015 1 AbeDavis_2015 580.01 585.14 <NA> <unk> and we were able to do this so well that i could even shazam our results
AbeDavis_2015 1 AbeDavis_2015 607.03 610.94 <NA> <unk> we can also push things by changing the hardware that we use 
AbeDavis_2015 1 AbeDavis_2015 610.94 620.66 <NA> because the experiments i 've shown you so far were done with a camera a high speed camera that can record video about a one hundred times faster than most cell phones <unk> 
AbeDavis_2015 1 AbeDavis_2015 620.23 625.2 <NA> but we 've also found a way to use this technique with more regular cameras
AbeDavis_2015 1 AbeDavis_2015 625.49 629.52 <NA> <unk> and we do that by taking advantage of what 's called a rolling shutter 
AbeDavis_2015 1 AbeDavis_2015 629.45 638.11 <NA> you see most cameras record images one row at a time <unk> and so if an object moves during
AbeDavis_2015 1 AbeDavis_2015 637.66 644.27 <NA> the recording of a single image <unk> there 's a slight time delay between each row <unk> and this causes
AbeDavis_2015 1 AbeDavis_2015 644.08 650.81 <NA> slight artifacts that get coded into each frame of a video <unk> and so what we found
AbeDavis_2015 1 AbeDavis_2015 650.81 654.97 <NA> is that by analyzing these artifacts we can actually recover sound
AbeDavis_2015 1 AbeDavis_2015 654.6 657.83 <NA> <unk> sound using a modified version of our algorithm <unk> 
AbeDavis_2015 1 AbeDavis_2015 657.83 666.34 <NA> so here 's an experiment we did where we filmed a bag of candy while a nearby loudspeaker played the same mary had a little lamb music from before <unk> 
AbeDavis_2015 1 AbeDavis_2015 666 670.12 <NA> but this time we used just a regular store bought camera 
AbeDavis_2015 1 AbeDavis_2015 669.93 674.84 <NA> and so in a second i 'll play for you the sound that we recovered and it 's going to sound distorted this
AbeDavis_2015 1 AbeDavis_2015 698.8 700.23 <NA> <unk> that sounds distorted
AbeDavis_2015 1 AbeDavis_2015 701.63 703.89 <NA> <unk> what 's really amazing here
AbeDavis_2015 1 AbeDavis_2015 703.43 709.65 <NA> is that we were able to do this with something that you could literally run out and pick up at a best buy <unk> 
AbeDavis_2015 1 AbeDavis_2015 710.6 718.53 <NA> so at this point a lot of people see this work and they immediately think about surveillance <unk> and
AbeDavis_2015 1 AbeDavis_2015 718.61 724.74 <NA> to be fair it 's not hard to imagine how you might use this technology to spy on someone <unk> but
AbeDavis_2015 1 AbeDavis_2015 724.74 729.97 <NA> keep in mind that there 's already a lot of very mature technology out there for surveillance in fact
AbeDavis_2015 1 AbeDavis_2015 730.13 735.22 <NA> people have been using lasers to eavesdrop on objects from a distance for decades <unk> 
AbeDavis_2015 1 AbeDavis_2015 735.51 743.47 <NA> but what 's really new here what 's really different is that now we have a way to picture the vibrations of an object 
AbeDavis_2015 1 AbeDavis_2015 743.13 746.89 <NA> which gives us a new lens through which to look at the world <unk> 
AbeDavis_2015 1 AbeDavis_2015 746.46 753.4 <NA> and we can use that lens to learn not just about forces like sound that cause an object to vibrate <unk> 
AbeDavis_2015 1 AbeDavis_2015 753.09 754.88 <NA> but also about the object
AbeDavis_2015 1 AbeDavis_2015 754.81 756.17 <NA> <unk> itself <unk> 
AbeDavis_2015 1 AbeDavis_2015 756.61 762.35 <NA> and so i want to take a step back and and think about how that might change the ways that we use video <unk> 
AbeDavis_2015 1 AbeDavis_2015 762.16 770.21 <NA> because we usually use video to look at things and i 've just shown you how we can use it to listen to things <unk> 
AbeDavis_2015 1 AbeDavis_2015 770.05 776.21 <NA> but there 's another important way that we learn about the world that 's by interacting with it 
AbeDavis_2015 1 AbeDavis_2015 776.11 779.94 <NA> we push and pull and poke and prod things we
AbeDavis_2015 1 AbeDavis_2015 780.13 786.6 <NA> shake things and see what happens <unk> and that 's something that video still won 't let us do 
AbeDavis_2015 1 AbeDavis_2015 786.8 789 <NA> at least not traditionally <unk> 
AbeDavis_2015 1 AbeDavis_2015 789.14 797.31 <NA> so i want to show you some new work <unk> and this is based on an idea i had just a few months ago <unk> so this is actually the first time i 've shown it to a public audience <unk> 
AbeDavis_2015 1 AbeDavis_2015 797.03 802.99 <NA> and the basic idea is that we 're going to use the vibrations in a video
AbeDavis_2015 1 AbeDavis_2015 802.75 804.97 <NA> to capture objects in a way that
AbeDavis_2015 1 AbeDavis_2015 804.96 807.13 <NA> <unk> will let us interact with them
AbeDavis_2015 1 AbeDavis_2015 806.96 809.8 <NA> and see how they react to us <unk>
AbeDavis_2015 1 AbeDavis_2015 810.66 816.28 <NA> so here 's an object and in this case it 's a wire figure in the shape of a human <unk> 
AbeDavis_2015 1 AbeDavis_2015 816.03 824.35 <NA> and we 're going to film that object with just a regular camera <unk> so there 's nothing special about this camera in fact i 've actually done this with my cell phone before <unk> 
AbeDavis_2015 1 AbeDavis_2015 824.25 829.97 <NA> but we do want to see the object vibrate <unk> so to make that happen we 're just going to bang a little bit on the surface
AbeDavis_2015 1 AbeDavis_2015 829.69 833 <NA> <unk> surface where it 's resting while we record this video
AbeDavis_2015 1 AbeDavis_2015 838.66 844.91 <NA> so that 's it just five seconds of regular video <unk> while we bang on this surface <unk> 
AbeDavis_2015 1 AbeDavis_2015 844.6 848.7 <NA> and we 're going to use the vibrations in that video
AbeDavis_2015 1 AbeDavis_2015 848.47 854.82 <NA> to learn about the structural and material properties of our object and we 're going to use that information
AbeDavis_2015 1 AbeDavis_2015 854.87 857.97 <NA> to create something new and interactive <unk> 
AbeDavis_2015 1 AbeDavis_2015 864.41 867.34 <NA> and so here 's what we 've created 
AbeDavis_2015 1 AbeDavis_2015 867.34 873.03 <NA> and it looks like a regular image <unk> but this isn 't an image and it 's not a video <unk> 
AbeDavis_2015 1 AbeDavis_2015 872.54 877.66 <NA> because now i can take my mouse and i can start interacting with the object
AbeDavis_2015 1 AbeDavis_2015 884.64 887.23 <NA> and so what you see here
AbeDavis_2015 1 AbeDavis_2015 886.92 893.62 <NA> is a simulation of how this object would respond to new forces that we 've never seen before <unk> 
AbeDavis_2015 1 AbeDavis_2015 893.46 897.56 <NA> and we created it from just five seconds of regular video
AbeDavis_2015 1 AbeDavis_2015 909.67 917.48 <NA> <unk> so this is a really powerful way to look at the world <unk> because it lets us predict how objects will respond to new situations <unk> 
AbeDavis_2015 1 AbeDavis_2015 917.05 921.21 <NA> and you could imagine for instance looking at an old bridge
AbeDavis_2015 1 AbeDavis_2015 921.04 925.02 <NA> and wondering what would happen how would that bridge hold up if i were
AbeDavis_2015 1 AbeDavis_2015 925 932.79 <NA> drive my car across it and that 's a question that you probably want to answer before you start driving across that bridge 
AbeDavis_2015 1 AbeDavis_2015 933.65 940.29 <NA> and of course there are going to be limitations to this technique just like there were with the visual microphone <unk> but
AbeDavis_2015 1 AbeDavis_2015 939.92 944.58 <NA> we found that it works in a lot of situations that you might not expect <unk> 
AbeDavis_2015 1 AbeDavis_2015 944.21 952.02 <NA> especially if you give it longer videos <unk> so for example here 's a video that i captured of a bush outside of my apartment <unk> 
AbeDavis_2015 1 AbeDavis_2015 951.89 954.43 <NA> and i didn 't do anything to this bush
AbeDavis_2015 1 AbeDavis_2015 955.2 961.75 <NA> <unk> but by capturing a minute long video a gentle breeze caused enough vibrations
AbeDavis_2015 1 AbeDavis_2015 961.26 965.47 <NA> that we could learn enough about this bush to create this simulation 
AbeDavis_2015 1 AbeDavis_2015 972.63 974.96 <NA> and so you could imagine giving this
AbeDavis_2015 1 AbeDavis_2015 976.12 983.21 <NA> <unk> and letting him control <unk> say the strength and direction of wind in a shot after it 's been recorded 
AbeDavis_2015 1 AbeDavis_2015 984.19 989.27 <NA> or in this case <unk> we pointed our camera at a hanging curtain <unk> 
AbeDavis_2015 1 AbeDavis_2015 988.93 992.84 <NA> and you can 't even see any motion in this video <unk> 
AbeDavis_2015 1 AbeDavis_2015 992.74 1000.17 <NA> but by recording a two minute long video <unk> natural air currents in this room created enough subtle
AbeDavis_2015 1 AbeDavis_2015 1000.13 1005.96 <NA> <unk> imperceptible motions and vibrations that we could learn enough to create this simulation <unk> 
AbeDavis_2015 1 AbeDavis_2015 1007.78 1009.02 <NA> and
AbeDavis_2015 1 AbeDavis_2015 1009.01 1015.99 <NA> ironically we 're kind of used to having this kind of interactivity when it comes to virtual objects 
AbeDavis_2015 1 AbeDavis_2015 1015.99 1019.46 <NA> when it comes to video games and 3d models <unk> 
AbeDavis_2015 1 AbeDavis_2015 1019.06 1025.23 <NA> but to be able to capture this information from real objects in the real world using just simple
AbeDavis_2015 1 AbeDavis_2015 1026.63 1031.5 <NA> <unk> is something new that has a lot of potential <unk> so
AbeDavis_2015 1 AbeDavis_2015 1031.19 1035.88 <NA> here are the amazing people who worked with me on these projects applause
AbeDavis_2015 1 AbeDavis_2015 1043.73 1045.45 <NA> and what i 've shown you <unk>
AbeDavis_2015 1 AbeDavis_2015 1045.35 1052.32 <NA> <unk> today is only the beginning <unk> we 've just started to scratch the surface of what you can do with this kind of imaging <unk> 
AbeDavis_2015 1 AbeDavis_2015 1054.92 1059.68 <NA> to capture our surroundings with common accessible technology <unk> 
AbeDavis_2015 1 AbeDavis_2015 1059.34 1065.48 <NA> and so looking to the future it 's going to be really exciting to explore what this can tell us about the world
