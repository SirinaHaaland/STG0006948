GradyBooch_2016S 1 GradyBooch_2016S 21.13 24.53 <NA> <unk> and you sir who laughed the loudest you probably still are 
GradyBooch_2016S 1 GradyBooch_2016S 25.75 29.52 <NA> i grew up in a small town in the dusty plains of north texas
GradyBooch_2016S 1 GradyBooch_2016S 29.9 35.61 <NA> <unk> son of a sheriff who was the son of a pastor <unk> getting into trouble was not an option
GradyBooch_2016S 1 GradyBooch_2016S 35.39 40.17 <NA> <unk> and so i started reading calculus books for fun 
GradyBooch_2016S 1 GradyBooch_2016S 40.4 49.74 <NA> you did too that led me to building a laser and a computer and model rockets <unk> and that led me to making rocket fuel in my bedroom <unk> 
GradyBooch_2016S 1 GradyBooch_2016S 51.93 57.22 <NA> <unk> in scientific terms <unk> we call this a very bad idea 
GradyBooch_2016S 1 GradyBooch_2016S 57.72 60.07 <NA> around that same time <unk> 
GradyBooch_2016S 1 GradyBooch_2016S 60.03 66.31 <NA> stanley kubrick 's two thousand and one a space odyssey came to the theaters and my life was forever changed <unk> 
GradyBooch_2016S 1 GradyBooch_2016S 65.88 76.34 <NA> i loved everything about that movie <unk> especially the hal nine thousand now hal was a sentient computer designed to guide the discovery spacecraft from
GradyBooch_2016S 1 GradyBooch_2016S 76.1 79.88 <NA> the earth to jupiter hal was also a flawed character
GradyBooch_2016S 1 GradyBooch_2016S 80.05 84.86 <NA> <unk> for in the end he chose to value the mission over human life 
GradyBooch_2016S 1 GradyBooch_2016S 84.4 97.25 <NA> now hal was a fictional character <unk> but nonetheless he speaks to our fears our fears of being subjugated by some unfeeling artificial intelligence who is indifferent to our humanity <unk> 
GradyBooch_2016S 1 GradyBooch_2016S 97.39 100.08 <NA> i believe that such fears are unfounded
GradyBooch_2016S 1 GradyBooch_2016S 101 104.55 <NA> <unk> we stand at a remarkable time in human history <unk> 
GradyBooch_2016S 1 GradyBooch_2016S 104.38 109.58 <NA> where <unk> driven by refusal to accept the limits of our bodies and our minds 
GradyBooch_2016S 1 GradyBooch_2016S 109.59 119.34 <NA> we are building machines of exquisite <unk> beautiful complexity and grace that will extend the human experience in ways beyond our imagining 
GradyBooch_2016S 1 GradyBooch_2016S 119.24 124.9 <NA> after a career that led me from the air force academy to space command to now <unk> i became a
GradyBooch_2016S 1 GradyBooch_2016S 125 131.15 <NA> systems engineer and recently i was drawn into an engineering problem associated with nasa 's mission to mars <unk> 
GradyBooch_2016S 1 GradyBooch_2016S 130.94 142.41 <NA> now <unk> in space flights to the moon we can rely upon mission control in houston to watch over all aspects of a flight <unk> however mars is two hundred times further away <unk> 
GradyBooch_2016S 1 GradyBooch_2016S 142.41 149.99 <NA> and as a result it takes on average thirteen minutes for a signal to travel from the earth to mars if there 's trouble
GradyBooch_2016S 1 GradyBooch_2016S 151.15 160.82 <NA> <unk> there 's not enough time and so a reasonable engineering solution calls for us to put mission control inside the walls of the orion spacecraft 
GradyBooch_2016S 1 GradyBooch_2016S 160.54 174.14 <NA> another fascinating idea in the mission profile places humanoid robots on the surface of mars before the humans themselves arrive first to build facilities and later to serve as collaborative members of the science team 
GradyBooch_2016S 1 GradyBooch_2016S 176 181.15 <NA> <unk> as i looked at this from an engineering perspective it became very clear to me that what i needed to architect
GradyBooch_2016S 1 GradyBooch_2016S 181.15 190.05 <NA> was a smart collaborative socially intelligent artificial intelligence in other words i needed to build something very much like a hal
GradyBooch_2016S 1 GradyBooch_2016S 189.77 192.99 <NA> but without the homicidal tendencies 
GradyBooch_2016S 1 GradyBooch_2016S 194.45 200.11 <NA> let 's pause for a moment is it really possible to build an artificial intelligence
GradyBooch_2016S 1 GradyBooch_2016S 202.08 211.44 <NA> <unk> in many ways this is a hard engineering problem with elements of ai not some wet hair ball of an ai problem that needs to be engineered 
GradyBooch_2016S 1 GradyBooch_2016S 211.28 213.97 <NA> to paraphrase alan turing
GradyBooch_2016S 1 GradyBooch_2016S 213.8 218.2 <NA> <unk> i 'm not interested in building a sentient machine i 'm not building a hal 
GradyBooch_2016S 1 GradyBooch_2016S 218.2 224.41 <NA> all i 'm after is a simple brain something that offers the illusion of intelligence 
GradyBooch_2016S 1 GradyBooch_2016S 225 235.19 <NA> <unk> the art and the science of computing have come a long way since hal was onscreen and i 'd imagine if his inventor dr chandra were here today he 'd have a whole lot of questions for us 
GradyBooch_2016S 1 GradyBooch_2016S 234.79 244.99 <NA> is it really possible for us to take a system of millions upon millions of devices to read in their data streams to predict their failures and act in advance 
GradyBooch_2016S 1 GradyBooch_2016S 244.99 246.23 <NA> yes <unk> 
GradyBooch_2016S 1 GradyBooch_2016S 245.77 250.08 <NA> can we build systems that converse with humans in natural language <unk> yes
GradyBooch_2016S 1 GradyBooch_2016S 250.22 257.02 <NA> <unk> can we build systems that recognize objects identify emotions emote themselves play games and even read lips 
GradyBooch_2016S 1 GradyBooch_2016S 257.02 265.35 <NA> yes <unk> can we build a system that sets goals that carries out plans against those goals and learns along the way yes <unk> 
GradyBooch_2016S 1 GradyBooch_2016S 264.89 267.13 <NA> can we build systems
GradyBooch_2016S 1 GradyBooch_2016S 266.68 274.47 <NA> that have a theory of mind this we are learning to do can we build systems that have an ethical and moral foundation 
GradyBooch_2016S 1 GradyBooch_2016S 273.98 276.96 <NA> this we must learn how to do 
GradyBooch_2016S 1 GradyBooch_2016S 276.86 279.97 <NA> so let 's accept for a moment that it 's possible to build
GradyBooch_2016S 1 GradyBooch_2016S 279.93 287.86 <NA> <unk> such an artificial intelligence for this kind of mission and others the next question you must ask yourself is should we fear it 
GradyBooch_2016S 1 GradyBooch_2016S 287.4 292.75 <NA> now <unk> every new technology brings with it some measure of trepidation 
GradyBooch_2016S 1 GradyBooch_2016S 292.29 304.97 <NA> when we first saw cars people lamented that we would see the destruction of the of the family when we first saw telephones come in people were worried it would destroy all civil conversation at a point in time
GradyBooch_2016S 1 GradyBooch_2016S 304.78 318.42 <NA> <unk> time we saw the written word become pervasive people thought we would lose our ability to memorize these things are all true to a degree <unk> but it 's also the case that these technologies brought to us things that extended the human experience
GradyBooch_2016S 1 GradyBooch_2016S 318.21 320.99 <NA> in some profound ways 
GradyBooch_2016S 1 GradyBooch_2016S 321.31 329.46 <NA> so let 's take this a little further <unk> i do not fear the creation of an ai like this
GradyBooch_2016S 1 GradyBooch_2016S 329.84 342.9 <NA> <unk> because it will eventually embody some of our values <unk> consider this building a cognitive system is fundamentally different than building a traditional software intensive system of the past we don 't program them <unk> we teach them <unk> 
GradyBooch_2016S 1 GradyBooch_2016S 342.9 352.36 <NA> in order to teach a system how to recognize flowers i show it thousands of flowers of the kinds i like <unk> in order to teach a system how to play a game well i would you would
GradyBooch_2016S 1 GradyBooch_2016S 355.11 356.89 <NA> <unk> flowers come on 
GradyBooch_2016S 1 GradyBooch_2016S 356.91 366.32 <NA> to teach a system how to play a game like go i 'd have it play thousands of games of go <unk> but in the process i also teach it how to discern a good game from a bad game 
GradyBooch_2016S 1 GradyBooch_2016S 366.32 375.05 <NA> if i want to create an artificially intelligent legal assistant i will teach it some corpus of law but at the same time i am fusing with it the
GradyBooch_2016S 1 GradyBooch_2016S 375 378.26 <NA> sense of mercy and justice that is part of that law <unk> 
GradyBooch_2016S 1 GradyBooch_2016S 378.07 388.32 <NA> in scientific terms this is what we call ground truth and here 's the important point in producing these machines we are therefore teaching them a sense of our values 
GradyBooch_2016S 1 GradyBooch_2016S 388.32 395.72 <NA> to that end i trust an artificial intelligence the same if not more as a human who is well trained 
GradyBooch_2016S 1 GradyBooch_2016S 395.56 398.6 <NA> but you may ask what about
GradyBooch_2016S 1 GradyBooch_2016S 398.62 399.99 <NA> rogue agents
GradyBooch_2016S 1 GradyBooch_2016S 403.31 413.76 <NA> <unk> i do not fear an artificial intelligence in the hand of a lone wolf clearly <unk> we cannot protect ourselves against all random acts of violence but the reality is such a system <unk>
GradyBooch_2016S 1 GradyBooch_2016S 413.71 423.9 <NA> requires substantial training and subtle training far beyond the resources of an individual and furthermore it 's far more than just injecting an internet virus to the world <unk>
GradyBooch_2016S 1 GradyBooch_2016S 423.85 428.98 <NA> where you push a button all of a sudden it 's in a million places and laptops start blowing up all over the place
GradyBooch_2016S 1 GradyBooch_2016S 429.84 434.08 <NA> <unk> these kinds of substances are much larger and we 'll certainly see them coming 
GradyBooch_2016S 1 GradyBooch_2016S 433.98 443.36 <NA> do i fear that such an artificial intelligence might threaten all of humanity <unk> if you look at movies such as the matrix
GradyBooch_2016S 1 GradyBooch_2016S 454.9 463.64 <NA> <unk> on this theme and observes that a superintelligence might not only be dangerous it could represent an existential threat to all of humanity 
GradyBooch_2016S 1 GradyBooch_2016S 463.64 466.07 <NA> dr bostrom 's basic argument
GradyBooch_2016S 1 GradyBooch_2016S 465.58 474.88 <NA> is that such systems will eventually have such an insatiable thirst for information that they will perhaps learn how to learn
GradyBooch_2016S 1 GradyBooch_2016S 474.88 479.19 <NA> and eventually discover that they may have goals that are contrary to human needs
GradyBooch_2016S 1 GradyBooch_2016S 479.99 489.81 <NA> <unk> dr bostrom has a number of followers he is supported by people such as elon musk and and stephen hawking with all due respect
GradyBooch_2016S 1 GradyBooch_2016S 489.65 492 <NA> to these brilliant minds <unk> 
GradyBooch_2016S 1 GradyBooch_2016S 491.99 500.68 <NA> i believe that they are fundamentally wrong <unk> now there are a lot of pieces of dr bostrom 's argument to unpack and i don 't have time to unpack them all but
GradyBooch_2016S 1 GradyBooch_2016S 500.46 504.97 <NA> very briefly consider this super knowing is very different than super
GradyBooch_2016S 1 GradyBooch_2016S 505.17 514.09 <NA> <unk> doing hal was a threat to the discovery crew only insofar as hal commanded all aspects of the discovery so it would have to be with a <unk>
GradyBooch_2016S 1 GradyBooch_2016S 515.28 521.2 <NA> <unk> would have to have dominion over all of our world this is the stuff of skynet from the movie the terminator in which we had a <unk>
GradyBooch_2016S 1 GradyBooch_2016S 522.23 529.85 <NA> that commanded human will that directed every device that was in every corner of the world <unk> practically speaking it ain 't
GradyBooch_2016S 1 GradyBooch_2016S 529.81 536.19 <NA> <unk> gonna happen <unk> we are not building ais that control the weather that direct the tides that
GradyBooch_2016S 1 GradyBooch_2016S 536.01 542.85 <NA> command us capricious chaotic humans and furthermore if such an artificial intelligence existed 
GradyBooch_2016S 1 GradyBooch_2016S 542.85 548.96 <NA> it would have to compete with human economies and thereby compete for resources with us 
GradyBooch_2016S 1 GradyBooch_2016S 548.71 552.14 <NA> and in the end don 't tell siri this
GradyBooch_2016S 1 GradyBooch_2016S 551.95 553.68 <NA> we can always unplug them
GradyBooch_2016S 1 GradyBooch_2016S 556.88 563.85 <NA> we are on an incredible journey of coevolution with our machines the humans we are
GradyBooch_2016S 1 GradyBooch_2016S 563.65 572.02 <NA> today are not the humans we will be then to worry now about the rise of a superintelligence is in many ways
GradyBooch_2016S 1 GradyBooch_2016S 572.02 579.97 <NA> a dangerous distraction because the rise of computing itself brings to us a number of human and societal issues to which we must now
GradyBooch_2016S 1 GradyBooch_2016S 580.05 583.98 <NA> <unk> attend how shall i best organize society
GradyBooch_2016S 1 GradyBooch_2016S 583.79 596.35 <NA> when the need for human labor diminishes how can i bring understanding and education throughout the globe and still respect our differences how might i extend and enhance human life through cognitive healthcare <unk> 
GradyBooch_2016S 1 GradyBooch_2016S 596.35 598.16 <NA> how might i
GradyBooch_2016S 1 GradyBooch_2016S 597.94 604.97 <NA> use computing to help take us to the stars <unk> and that 's the exciting thing the opportunities
GradyBooch_2016S 1 GradyBooch_2016S 605.4 615.03 <NA> to use computing to advance the human experience are within our reach here and now <unk> and we are just beginning <unk> thank you very much
