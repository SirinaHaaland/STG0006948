  i 'm joy  a poet of code on a mission
 to stop an unseen force that 's rising a force that i called the coded gaze my term for algorithmic bias 
 algorithmic bias like human bias
  results in unfairness  however  algorithms like viruses can spread bias on a massive scale at a rapid pace 
 algorithmic bias can also lead to exclusionary experiences and discriminatory practices  let me show you what i mean
  so how did this happen why am i sitting in front of a computer in a white mask  trying to be detected by a cheap webcam
  not fighting the coded gaze as a poet of code i 'm a graduate student at the mit media lab  and there i have the opportunity to work on all sorts of whimsical 
  projects including the aspire mirror a project i did so i could project digital masks onto my reflection so in the morning if i wanted to feel
  i could put on a lion if i wanted to be uplifted i might have a quote  so i used generic facial recognition software to build the system  but found it was really hard to test it unless i wore a white mask  
 unfortunately i 've run into this issue before 
 when i was an undergraduate at georgia tech studying computer science i used to work on social robots and one of my tasks was to get a robot to play
  peek a boo a simple turn taking game where partners cover their face and then uncover it saying peek a boo 
 the problem is peek a boo doesn 't really work if i can 't see you and my robot couldn 't see me  but i borrowed my roommate 's face to get the project done  submitted the assignment and figured you know
  somebody else will solve this problem 
 not too long after i was in hong kong for an entrepreneurship competition 
 the organizers decided to take participants on a tour of local start ups one of the  start ups had a social robot and they decided to do a demo 
  the demo worked on everybody until it got to me  and you can probably guess it 
  it couldn 't detect my face  
 i asked the developers what was going on and it turned out we had used the same generic facial recognition software  
 halfway around the world i learned that algorithmic bias can travel as quickly as it takes to download some files off of the internet  
 so what 's going on why isn 't my face being detected well we have to look at how we give machines sight computer vision uses machine learning techniques
 to do facial recognition so how this works is you create a training set with examples of faces this is a face this is a face  this is not a face and over time you can 
  teach a computer how to recognize other faces  however if the training sets aren 't really that diverse any face that deviates too much from the established norm will be harder to detect which is what was happening to me
  but don 't worry there 's some good news training sets don 't just materialize out of nowhere we actually can create them so there 's an opportunity to create full spectrum training sets that reflect a richer portrait of humanity 
 now you 've seen in my examples how social robots was how i found out about exclusion with algorithmic bias  but algorithmic bias
  can also lead to discriminatory practices  
 across the us  police departments are starting to use facial recognition software in their crime fighting arsenal 
 georgetown law published a report showing that one in two adults in the us that 's one hundred and seventeen million people have their faces in facial recognition networks
  police departments can currently look at these networks unregulated using algorithms that have not been audited for accuracy  
 yet we know facial recognition is not fail proof and labeling faces consistently remains a challenge you might have seen this on facebook my 
  friends and i laugh all the time when we see other people mislabeled in our photos but
  misidentifying a suspected criminal is no laughing matter  nor is breaching civil liberties 
 machine learning is being used for facial recognition but it 's also extending beyond the realm of computer vision 
 in her book
  wmds
 widespread  mysterious and destructive algorithms that are increasingly being used to make decisions that impact more aspects of our lives  
 so who gets hired or fired do you get that loan do you get insurance are you admitted into the college you wanted to get into do you and i pay the same price for the same product purchased on the same
  platform law enforcement is also starting to use machine learning for predictive policing some judges use 
  risk scores to determine how long an individual is going to spend in prison  so we really have to think about these decisions are they fair 
 and we 've seen that algorithmic bias doesn 't necessarily always lead to fair outcomes
  so what can we do about it well
 we can start thinking about how we create more inclusive code and employ inclusive coding practices  it really starts with people 
 so who codes matters are we creating
  teams with diverse individuals who can check each other 's blind spots
  on the technical side how we code matters  are we factoring in fairness as we 're developing systems  and finally  why we code matters 
  we 've used tools of computational creation to unlock immense wealth we now have the opportunity to unlock even greater equality if 
  we make social change a priority and not an afterthought  
 who codes matters how we code matters and why we code matters  so to go towards incoding we can start thinking about building platforms that can identify 
 bias by collecting people 's experiences like the ones i shared but also auditing existing software 
  campaign where you and i can help developers test and create more inclusive training sets  
 and we can also start thinking more conscientiously about the social impact of the technology that we 're developing 
 to get the incoding movement started  i 've launched the algorithmic justice league where anyone who cares about fairness can help fight the coded gaze
  gaze on 
  you can report bias request audits become a tester and join the ongoing conversation
 so i invite you to join me in creating a world where technology works for all of us not just some of
  a world where we value inclusion and center social change thank you 
 but i have one question will you join me in the
