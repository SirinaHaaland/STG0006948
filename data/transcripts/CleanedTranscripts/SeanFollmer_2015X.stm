  we 've evolved with tools  and tools have evolved with us our ancestors created these hand axes one point five million years ago  shaping them to not only fit the task at hand but also
  over the years tools have become more and more specialized 
 these sculpting tools have evolved through their use  and each one has a different form which matches its function  and they leverage the dexterity of our hands in order to manipulate things with much more precision 
 but as tools have become more and more complex we need more complex
  and so designers have become very adept at creating interfaces that allow you to manipulate parameters while you 're attending to other things such as taking a photograph and changing the focus or the aperture  
 but the computer has fundamentally changed the way we think about tools because computation is dynamic  
 so it can do a million different things and run a million different applications  however computers have the same static physical
  form for all of these different applications and the same static interface elements as well  and i believe that this is fundamentally a problem because it doesn 't really allow us to interact 
 with our hands and capture the rich dexterity that we have in our bodies  
  physically adapt to us and allow us to interact in new ways  and so that 's what i 've been doing at the mit media lab and now at stanford  
 so with my colleagues  daniel leithinger and hiroshi ishii we created inform 
 where the interface can actually come off the screen and you can physically manipulate it  
 or you can visualize 3d information physically and touch it and feel it to understand it in new ways
 or you can interact through gestures and direct deformations to sculpt digital clay  
 or interface elements can arise out of the surface and change on demand and the idea is that for each individual application the physical form
  matched to the application  
 and i believe this represents a new way that we can interact with information by making it physical 
 so the question is how can we use this
 traditionally urban planners and architects build physical models of cities and buildings to better understand them  so with tony tang at the media lab  we created an interface built on inform to allow urban planners to design and view
 entire cities and now you can walk around it  but it 's dynamic it 's physical  and you can also interact directly or you can look at different views  
 such as population or traffic information  but it 's made physical  
 we also believe that these dynamic shape displays can really change the ways that we
  remotely collaborate with people so when we 're working together in person i 'm not only looking at your face but i 'm also gesturing and manipulating objects and that 's really hard to do when you 're using tools like skype
  and so using inform you can reach out from the screen and manipulate things at a distance  so we used the pins of the display to represent people 's hands  allowing them to actually touch and manipulate objects at a distance
  and you can also manipulate and collaborate on 3d data sets as well so you can gesture around them as well as manipulate them and that allows people to collaborate on 
  these new types of 3d information in a richer way than might be possible with traditional tools  
  and those will be captured on one side and transmitted to the other or you can have an object that 's linked between two places so as i move a ball on one side the ball moves on the other as well  
 and so we do this by capturing the remote user using a depth sensing camera like a microsoft kinect 
 now you might be wondering how does this all work and essentially what it is is nine hundred linear actuators
 that are connected to these mechanical linkages that allow motion down here to be propagated
  in these pins above  so it 's not that complex compared to what 's going on at cern  but it did take a long time for us to build it 
 and so we started with a single motor a single linear actuator  
 and then we had to design a custom circuit board to control them and then we had to make a lot of them and so the problem with having nine hundred of something is that you have to do every step nine hundred times  and so that meant that we
  had a lot of work to do so we sort of set up a
 the media lab and brought undergrads in and convinced them to do research laughter
 and had late nights watching movies eating pizza and screwing in thousands of screws you know research 
 laughter but anyway  i think that we were really excited by the things that inform allowed us to do increasingly we 're using mobile devices
  we interact on the go  but mobile devices just like computers 
 are used for so many different applications so you use them to talk on the phone to surf the web to play games to take pictures or even a million different things  but again they have 
  the same static physical form for each of these applications  and so we wanted to know how
 we take some of the same interactions that we developed for inform and bring them to mobile devices  so at stanford we created this haptic edge display  
 which is a mobile device with an array of linear actuators that can change shape so you can feel in your hand where you are as you 're reading a book  
 or you can feel in your pocket new types of tactile sensations that are richer than the vibration or buttons can emerge from the side that allow you to interact where you want them to be
 or you can play games and have actual buttons  
 and so we were able to do this by embedding forty small tiny linear actuators inside the device and that allow you not only to touch them but also back drive them as well  
 but we 've also looked at other ways to create more complex shape change so we 've used pneumatic actuation to create a morphing device where you can go
  from something that looks a lot like a phone to a wristband on the go  
 and so together with ken nakagaki at the media lab we created this new
  we 're also interested in looking at ways that users can actually deform the interfaces to shape them into the devices that they want to use  so you can make something like a game controller  and then the system will understand what shape it 's in and change to that mode 
 so where does this point how do we move forward from here i think
  where we are today is in this new age of the internet of things where we have computers everywhere they 're in our pockets they 're in our walls  they 're in almost every device that you 'll buy in the next five years  
 but what if we stopped thinking about devices and think instead about environments  and so how can we have smart furniture or smart rooms or smart 
 environments or cities that can adapt to us physically and allow us to do new new ways of
  with people and doing new types of tasks so for the milan design week  we created transform which is an interactive 
  table scale version of these shape displays which can move physical objects on the surface for example reminding you to take your keys  but it can also transform
 to fit different ways of
  so if you want to work then it can change to sort of set up your work system and so as you bring a device over it creates all the affordances you need
 and brings other objects to help you accomplish those goals 
 so in conclusion i really think that we need to think about a new fundamentally different way of interacting with computers 
 we need computers that can physically adapt to us and adapt to the ways that we want to
  use them
 and really harness the rich dexterity that we have of our hands and our ability to think spatially about information by making it physical  
 but looking forward i think we need to go beyond this beyond devices to really think about new ways that we can bring people together and bring our information into 
  the world and think about smart environments that can adapt to us physically  so with that i will leave you thank you very much
