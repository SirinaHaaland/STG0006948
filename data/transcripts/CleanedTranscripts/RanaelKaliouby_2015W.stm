  our emotions influence every aspect of our lives from our health and how we learn to how we do business and make decisions big ones and small 
 our emotions also influence how we connect
  we 've evolved to live in a world like this  
 but instead we 're living more and more of our lives like this this is the text message from my daughter last night
 in a world that 's devoid of emotion  
 so i 'm on a mission to change that i want to bring emotions back into our digital experiences  
 i started on this path
  a computer scientist
 in egypt and i had just gotten accepted to a ph d program at cambridge university  
 so i did something quite unusual for a young newlywed muslim egyptian wife 
 with the support of my husband who had to stay in egypt  i packed my bags and i moved to england 
 at cambridge  thousands of miles away from home  i realized i was spending more hours with my laptop than i did with any other human
 yet despite this intimacy my laptop had absolutely no idea how i was feeling  it had no idea if i was happy
  having a bad day or stressed confused and so that got frustrating  
 even worse as i communicated online with my family back home  i felt that all my emotions disappeared in cyberspace
  homesick i was lonely and on some days i was actually crying  but all i had to communicate these emotions
 was this 
 today 's technology has lots of i q but no e q lots of cognitive intelligence but no emotional intelligence  
 so that got me thinking
  sense our emotions what if our devices could sense how we felt and reacted accordingly just the way an emotionally intelligent friend would 
 those questions led me and my team to create technologies that can read and respond to our emotions 
 and our starting point was the human face  
 so our human face happens to be one of the most powerful channels that we all use to
  communicate social and emotional states  everything from enjoyment  surprise  empathy and curiosity 
 in emotion science we call each facial muscle movement an action unit 
 so for example action unit twelve it 's not a hollywood blockbuster  it is
  actually a lip corner pull which is the main component of a smile try it everybody let 's get some smiles going on 
 another example is action unit four it 's the brow furrow it 's when you draw your eyebrows together and you create all these textures and wrinkles we don 't like them
  but it 's a strong indicator of a negative emotion  so we have about forty five of these action units  and they combine to express hundreds of emotions
  teaching a computer to read these facial emotions is hard  because these action units they can be fast they 're subtle
 and they combine in many different ways  so take for example the smile and the smirk 
 they look somewhat similar  but they mean very different things 
 so the smile is positive a smirk is often negative  sometimes a smirk can make you become famous  
  it 's important for a computer to be able to tell the difference between the two expressions  so how do we do that we give our algorithms
 tens of thousands of examples of people we know to be smiling from different ethnicities ages  genders  and we do the same for smirks  
 and then using deep learning the algorithm looks for all these textures and wrinkles and and shape changes on our face  and basically learns that all smiles have common characteristics
  smirks have subtly different characteristics  
 and the next time it sees a new face  it essentially learns that
 this face has the same characteristics of a smile and it says aha  i recognize this this is a smile expression 
 so the best way to demonstrate how this technology works is to try a live demo  so i need a volunteer preferably somebody with a face
 's going to be our volunteer today  
 so over the past five years we 've moved from being a research project at mit to a company  where my team has worked really hard to make this technology work as we like to say in the wild  
 and we 've also shrunk it so that the core emotion engine works on any mobile device with a camera like this ipad  so let 's give this a try
 as you can see the algorithm has essentially found cloe 's face so it 's this white bounding box and it 's tracking the main feature points on her face  so her eyebrows her eyes her mouth and her nose 
 the question is can it recognize her expression so we 're going to test the machine  so first of all give me your poker face yep awesome 
  and then as she smiles this is a genuine smile it 's great so you can see the green bar go up as she smiles now that was a big smile can you try a subtle smile to see if the computer can recognize 
 it does recognize subtle smiles as well we 've worked really hard to make that happen
  and then eyebrow raised indicator of surprise  brow furrow  which is an indicator of confusion 
 frown  yes
  so these are all the different action units there 's many more of them this is just a slimmed down demo  
 but we call each reading an emotion data point  
 and then they can fire together to portray different emotions so on the right side of the demo look like you 're happy  so that 's joy joy fires up  
 and then give me a disgust face try to remember what it was like when zayn left one direction
  the valence is actually quite negative so you must have been a big fan so valence is how positive or negative an experience is and engagement is how expressive she is as well 
 so imagine if cloe had access to this real time emotion stream and she could share it with anybody she wanted to 
 thank you
  we have amassed twelve billion of these emotion data points it 's the largest emotion database in the world 
 we 've collected it from two point nine million face videos 
 people who have agreed to share their emotions with us and from seventy five countries around the world it 's growing every day  
 it blows
  my mind away that we can now quantify something as personal as our emotions and we can do it at this scale  so what have we learned to date  
 gender 
 our data confirms something that you might suspect  
 women are more expressive than men not only do they smile more their smiles last longer and we can now really quantify what it is that that men and women respond to differently 
 let 's do culture so in the united states women are forty percent more expressive
  than men but curiously we don 't see any difference in the u k between men and women 
 laughter age  
 people who are fifty years and older are twenty five percent more emotive than younger people 
 women in their 20s smile a lot more than men the same
  a necessity for dating  but perhaps what surprised us the most about this data is that
 we happen to be expressive all the time  even when we are sitting in front of our devices alone  and it 's not just when we 're watching cat videos on facebook
  we are expressive when we 're emailing texting shopping online or even doing our taxes  
 where is this data used today in understanding how we engage with media so understanding virality and voting behavior
  and also empowering or emotion enabling technology and i want to share some examples that are especially close to my heart
  wearable glasses can help individuals who are visually impaired read the faces of others  
 and it can help individuals on the autism spectrum interpret emotion something that they really struggle with 
 in education imagine if
  your learning apps sense that you 're confused and slow down or that you 're bored  so it 's sped up just like a great teacher would in a classroom 
 what if your wristwatch tracked your mood or your car sensed that you 're tired  or perhaps your fridge knows that you 're stressed so
 what if when i was in cambridge  i had access to my real time emotion stream and i could share that with my family back home in a very natural way 
 just like i would 've if we were all in the same room together  
 i think five years down the line all our devices are going to have an emotion chip  
 and we won 't remember what it was like when we couldn 't just frown at our device and our device would say hmm you didn 't like that did you
 our biggest challenge is that there are so many applications of this technology my team and i realize that we can 't build them all ourselves so we 've made this technology available so that other developers can get building and get creative  
 we recognize that there are potential
 risks and potential for abuse  but
  having spent many years doing this 
 i believe that the benefits to humanity from having emotionally intelligent technology far outweigh the potential for misuse
 and i invite you all to be part of the conversation the more people who know about this technology the more we can all have a voice in how it 's being used  
 so as more and more of our lives become digital
  we are fighting a losing battle trying to curb our usage of devices in order to reclaim our emotions
  so what i 'm trying to do instead is to bring emotions into our technology and make our technologies more responsive so i want those devices that have separated us
 to bring us back together and by humanizing technology we have this golden opportunity
 to reimagine how we connect with machines  and therefore how we as human beings  connect with one another
