  we are built out of very small stuff  and we are embedded in a very large cosmos and the fact is that we are not very good at understanding 
  reality at either of those scales and that 's because our brains haven 't evolved to understand the world
 at that scale instead we 're trapped on this very thin slice of perception right in the middle  
 but it gets strange because even at that slice of reality that we call home we 're not seeing most of the action that 's going on 
 so take the colors of our world this
  electromagnetic radiation that bounces off objects and it hits specialized receptors in the back of our eyes  
 but we 're not seeing all the waves out there in fact what we see is less than a ten trillionth of what 's out there 
 so you have radio waves and microwaves and x rays and gamma rays passing through your body right now and you 're completely unaware of it  because you don 't come with the proper biological receptors
  for picking it up there are thousands of cell phone conversations passing through you right now and you 're utterly blind to it  
 now it 's not that these things are inherently
 snakes include some infrared in their reality and honeybees include ultraviolet in their view of the world
  and of course we build machines in the dashboards of our cars to pick up on signals in the radio frequency range  and we built machines in hospitals to pick up on the x ray range  
 but you can 't sense any of those by yourself at least not yet  because you don 't come equipped with the proper sensors 
 now what this means is that
 our experience of reality is constrained by our biology  and that goes against the common sense notion that
  our eyes and our ears and our fingertips are just picking up the objective reality that 's out there 
 instead our brains are sampling just a little bit of the world  
 now across the animal kingdom  different animals pick up on different parts of reality  so in the blind and deaf world of the tick
  the important signals are temperature and butyric acid 
 in the world of the black ghost knifefish its sensory world is is lavishly colored by electrical fields 
 and for the echolocating bat  its reality is constructed out of air compression waves 
 that 's the slice of their ecosystem that they can pick up on 
 and we have a word for this in science
  which is the german word for the surrounding world 
 now presumably  every animal assumes that its umwelt
 is the entire objective reality out there  because why would you ever stop to imagine that there 's something beyond what we can sense 
 instead what we all do is we accept reality as it 's presented to us
  your whole world is about smelling you 've got a long snout that has two hundred million scent receptors in it 
 and you have wet nostrils that attract and trap scent molecules  and your nostrils even have slits so you can take big nosefuls of air 
 everything is about smell for you 
 so one day  you stop in your tracks with a revelation you look at your human owner and you think
 what is it like to have the pitiful impoverished nose of a human 
 what is it like when you take a feeble little noseful of air how can you not know that there 's a cat one hundred yards away
  or that your neighbor was on this very spot six hours ago 
 so because we 're humans  we 've never experienced that world of smell
  so we don 't miss it  because we are firmly settled into our umwelt 
 but the question is do we have to be stuck there  
 so as a neuroscientist i 'm interested in the way that technology might expand our umwelt and how that 's going to change the experience of being human  
 so we already know that we can marry our
  technology to our biology 
 because there are hundreds of thousands of people walking around with artificial hearing and artificial vision  so the way this works is you take a microphone 
  and you digitize the signal  and you put an electrode strip directly into the inner ear 
 and
 as recently as fifteen years ago there were a lot of scientists who thought these technologies wouldn 't work 
 why it 's because these technologies speak the language of silicon valley  and it 's not exactly the same dialect as our natural biological sense organs  
 but the fact is that it works the brain figures out how to use the signals
 just fine  now how do we understand that well here 's the big secret 
 your brain is not hearing or seeing any of this  
 your brain is locked in a vault of silence and darkness inside your skull 
 all it ever sees are electrochemical signals that come in along different data cables  and this is all it has to
  with and nothing more  
 now  amazingly  the brain is really good at taking in these signals and extracting patterns and assigning meaning  
 so that it takes this inner cosmos and puts together a story of this  your subjective world
  but here 's the key point your brain doesn 't know and it doesn 't care  where it gets the data from 
 whatever information comes in it just figures out what to do with it  
 and this is a very efficient kind of machine it 's essentially a general purpose computing device  and it just takes in everything and figures 
  out what it 's going to do with it  and that i think frees up mother nature to
  tinker around with different sorts of input channels  
 so i call this the p h model of evolution  and i don 't want to get too technical here but p h stands for potato head  and
 i use this name to emphasize that all these sensors that we know and love like our eyes and our ears and our fingertips these
  you stick them in and you 're good to go the brain figures out what to do with the data that comes in  
 and when you look across the animal kingdom  you find lots of peripheral devices so snakes have heat pits with which to detect infrared and the ghost knifefish has 
  fingers on it with which it feels around and constructs a 3d model of the world 
 and many birds have magnetite so they can orient to the magnetic field of the planet  
 so what this means is that nature doesn 't have to continually redesign the brain  
 instead with the principles of brain
  all nature has to worry about is designing new peripherals  okay  so what this means is this the lesson that surfaces
 is that there 's nothing really special or fundamental about the biology that we come to the table with it 's just what we have inherited from a complex road of evolution  
 but it 's not what we have to stick
 stick with 
 and our best proof of principle of this comes from what 's called sensory substitution  
 and that refers to feeding information into the brain via unusual sensory channels  and the brain just figures out what to do with it 
 now that might sound speculative  but the first paper demonstrating this was published in the journal nature in one thousand nine hundred and sixty nine 
 so a scientist named paul
  put blind people in a modified dental chair  and he set up a video feed  and he put something in front of the camera and then you would feel that
 poked into your back with a grid of solenoids so if you wiggle a coffee cup in front of the camera you 're feeling that in your back and amazingly blind people got 
  pretty good at being able to determine what was in front of the camera just by feeling it in the small of their back 
  been many
 modern incarnations of this the sonic glasses take a video feed right in front of you and turn that into a sonic landscape  so as things move around and get closer and farther it sounds like bzz bzz bzz 
 it sounds like a cacophony 
 but after several weeks blind people start getting pretty good at understanding what 's in front of them just based on what they 're hearing 
  doesn 't have to be through the ears this system uses an electrotactile
 grid on the forehead so whatever 's in front of the video feed you 're feeling it on your forehead why the forehead because you 're not using it for much else
 the most modern incarnation is called the brainport and this is a little electrogrid that sits on your tongue  
 and the video feed gets turned into these little electrotactile signals and blind people get so
  good at using this that they can
 throw a ball into a basket or they can
 navigate complex obstacle courses they can come to see through their tongue now
 that sounds completely insane right but remember all vision ever is
 is electrochemical signals coursing around in your brain your brain doesn 't know where the
  signals come from it just figures out what to do with them so my interest in my lab is
 sensory substitution for the deaf  
 and this is a project i 've undertaken with a graduate student in my lab scott novich who is spearheading this for his thesis  
 and here is what we wanted to do
  we wanted to make it so that sound from the world gets converted in some way so that a deaf person can understand what is being said  
 and we wanted to do this  given the power and ubiquity of portable computing 
 we wanted to make sure that this would run on cell phones and tablets and also we wanted to make this a wearable something that you could wear under your clothing  
 so here 's
  as i 'm speaking my sound is getting captured by the tablet  and then it 's getting mapped onto a vest that 's covered in vibratory motors just like the motors
 in your cell phone  
 so as i 'm speaking  the sound is getting translated to a pattern of vibration on the vest 
  this is not just conceptual this tablet is transmitting bluetooth  and i 'm wearing the vest right now  so as i 'm speaking 
 the sound is getting translated into dynamic patterns of vibration i 'm feeling the sonic world around me  
 so we 've been testing this with deaf people now 
 and it turns out that after just a little bit of time people can start
 feeling they can start understanding the language of the vest  so this is jonathan he 's 
  a master 's degree he was born profoundly deaf which means that there 's a part of his umwelt that 's unavailable to him  
 so we had jonathan train with the vest for four days  two hours a day  and here he is on the fifth day
  so scott says a word jonathan feels it on the vest and he writes it on the board sn 
 where  
 where de jonathan is able to translate this complicated pattern of vibrations into an understanding of what 's being said
 jonathan is not doing this consciously because the patterns 
  are too complicated  but his brain is starting to unlock the pattern that allows it to figure out what the data mean  
  is that after wearing this for about three months he will have a direct perceptual experience of hearing
 in the same way that when a blind person passes a finger over braille  
 the meaning comes directly off the page without any conscious intervention at all 
 now this technology has the potential to be a game changer because the only other solution for deafness is a cochlear implant and that requires an invasive surgery
  can be built for forty times cheaper than a cochlear implant  which opens up this technology globally even for the poorest countries  
 now  
 we 've been very encouraged by our results with sensory substitution but what we 've been thinking a lot about is sensory addition how could we use a technology like this to add a completely new kind of sense to
  expand the human
 umvelt for example could we feed real time data from the internet directly into somebody 's brain and can they develop a direct perceptual experience  
 so here 's an experiment we 're doing in the lab a subject is feeling a real time streaming feed from the net of data for five
  two buttons appear  and he has to make a choice he doesn 't know what 's going on he makes a choice and he gets feedback after one second now here 's the thing the subject has no idea what all the 
  patterns mean but we 're seeing if he gets better at figuring out which button to press he doesn 't know that what we 're feeding is real time data from the stock market  
  and the feedback is telling him whether he did the right thing or not and what we 're seeing is can we expand the human 
  umvelt so that he comes to have after several weeks a direct perceptual experience of the economic movements of the planet 
 so we 'll report on that later to see how well this goes 
 here 's another thing we 're doing  during the talks this morning  we 've been automatically scraping twitter for the
 ted2015 hashtag  and we 've been doing an automated sentiment analysis which means are people using positive words or negative words or neutral 
 and while this has been going on  
 i have been feeling this and so i am plugged in to the aggregate emotion of thousands of people
 in real time  and that 's a new kind of human experience
  because now i can know how everyone 's doing and how much you 're loving this it
 's a bigger experience than a human can normally have 
 we 're also expanding the umvelt of pilots  so in this case the vest is streaming nine different measures from this quadcopter
  so pitch and yaw and roll and orientation and heading  and that improves this pilot 's ability to fly it it 's essentially like he 's extending his skin 
 up there far away  and that 's just the beginning what we 're envisioning is taking a modern cockpit full of gauges
  in a world of information now and there is a difference between accessing big data and experiencing it 
 so i think there 's really no end to the possibilities on the horizon for human expansion just imagine
 an astronaut being able to feel
  overall health of the international space station or
 for that matter having you feel the invisible states of your own health like your blood sugar and the state of your microbiome  or having 
  vision or seeing in infrared or ultraviolet 
 so the key is this  as we move into the future we 're going to increasingly be able to choose our own
  we no longer have to wait for mother nature 's sensory gifts on her timescales  
 but instead like any good parent  she 's given us the tools that we need to go out and define our own trajectory  
 so the question now is how do you want to go out and experience your universe  thank you
  first time i felt applause on the vest
  this could be the first experiment that
 secures its funding forevermore right 
 if successful de well that 's right i wouldn 't have to write to nih anymore ca well
 look just to be skeptical for a minute  i mean this is amazing but isn 't most of the evidence so far that that sensory substitution works not necessarily that sensory addition works i mean 
  the visual cortex is still there ready to process  and that that is needed as part of it de that
 's a great question we actually have no idea what the theoretical limits are of what kind of data the brain can take in the general story though is that it 's extraordinarily flexible so when a person goes blind 
 what we used to call their visual cortex gets taken
  over by other things by touch  by hearing by vocabulary  so what that tells us is that the cortex is kind of a one trick pony it just runs certain kinds of computations 
  on things  and when we look around at things like braille for example people are getting information through bumps on their fingers so
  there are so many possible applications for this are you ready for this what are you most excited about the direction it might go de i mean i think there 's a lot of applications here in terms of
 beyond sensory substitution  the things i started mentioning about astronauts on the space station they spend a lot of their time monitoring things and they could instead just get what 's going on because what this is really good for is multidimensional
  the key is this our visual systems are good at detecting blobs and edges but they 're really bad at what our world has become which is screens with lots and lots of data we have to crawl 
  that with our attentional systems  so this is a way of just feeling the state of something just like the way you know the state of your body as you 're standing around so i think heavy machinery safety feeling the state of a factory of your equipment that 's one place it 'll go right away
