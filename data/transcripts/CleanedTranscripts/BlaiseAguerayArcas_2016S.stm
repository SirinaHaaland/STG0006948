  i lead a team at google that works on machine intelligence  in other words  the engineering discipline of making computers and devices able to do some of the things that brains do 
 and this makes us interested
 in real brains and neuroscience as well  and especially interested in the
  things that our brains do that are still far superior to the performance of computers 
 historically one of those areas has been perception the process by which things out there in the world
 sounds and images can turn into concepts in the mind  this is essential for our own
  it 's also pretty useful on a computer  
 the machine perception algorithms for example that our team makes are what enable your pictures on google photos to become searchable 
 based on what 's in them  
 the flip side of perception is creativity  
 turning a concept into something out there into the world so over the past year our work on machine perception has also unexpectedly
 connected with the world of machine creativity and machine art
 i think michelangelo had a penetrating insight into to this dual relationship between perception and creativity  
 this is a famous quote of his every block of stone has a statue inside of it 
 and the job of the sculptor is to discover it 
 so i think that
 what michelangelo was getting at is that we create by perceiving and
  perception itself is an act of imagination and is the stuff of creativity  
 the organ that does all the thinking and perceiving and imagining of course is the brain  
 and i 'd like to begin with a brief bit of history about what we know about brains 
 because unlike say the heart or the intestines you really can 't say very much about a brain by just looking at it at least with the naked eye
  the early anatomists who looked at brains gave the superficial structures of this thing all kinds of fanciful names like hippocampus meaning little shrimp 
 but of course that sort of thing doesn 't tell us very much about what 's actually going on inside 
 the first person who i think really developed some kind of insight into what was going on in the brain
  who used microscopy and special stains that could selectively fill in or render in very high contrast the individual cells in the brain 
 in order to start to understand their morphologies  and
 these are the kinds of drawings that he made of neurons in the  19th century this is from from
  a bird brain and you see this incredible variety of different sorts of cells even the cellular theory itself was quite new at this point  
 and these structures these cells that have these arborizations these branches that can go very very long distances this was very novel at the time 
 they 're reminiscent of course of wires  that might have been obvious to some people in the  19th century the revolutions of wiring and electricity
  still in some ways unsurpassed  we 're still more than a century later trying to finish the job that ramn y cajal started these are raw data from our collaborators
 at the max planck institute of neuroscience and what our collaborators have done is to image
 little pieces
  entire sample here is about one cubic millimeter in size and i 'm showing you a very very small piece of it here that bar on the left is about one micron  the structures you see are mitochondria
 that are the size of bacteria  and these are consecutive slices through this
 through this very very tiny block of tissue  just for comparison 's sake the diameter of of an average strand of hair is about one hundred microns
  we 're looking at something much much smaller than a single strand of hair 
 and from these kinds of serial electron microscopy slices one can start to make reconstructions in 3d of neurons
 that look like these so these are sort of
 in the same style as ramn y cajal only a few neurons lit up because otherwise we wouldn 't be able to see anything here  it would be so crowded so full of of structure of wiring all connecting one
  was a little bit ahead of his time and progress on understanding the brain proceeded slowly over the next few decades 
 but we knew that neurons used electricity  and by world war ii our technology was advanced enough to start doing real electrical experiments on live neurons to better understand how they worked 
 this was the very same time when computers were being invented 
 very much based on the idea of modeling the brain of
  machinery as alan turing called it one of the fathers of computer science 
  warren mcculloch and walter pitts looked at ramn y cajal 's drawing of visual cortex which i 'm showing here
  this is the cortex that processes imagery that comes from the eye  and for them  this looked like a circuit diagram so
 there are a lot of details in mcculloch and pitts 's circuit
  diagram that are not quite right  but this basic idea that that visual cortex works like a series of computational elements that pass information one to the next in a cascade 
 is essentially correct 
 let 's talk for a moment about what a model for processing visual information would need to do 
 the basic task of perception is to take an image like this one
 and say
 that 's a bird which is a very simple thing for us to do with our brains but
 you should all understand that that for a computer this was pretty much impossible just a few years ago  
 the classical computing paradigm is not one in which this task is is easy to do 
 so what 's going on between the pixels between the image of the
  essentially a set of neurons connected to each other in a neural network as i 'm diagramming here  this neural network could be biological inside our visual cortices or nowadays we start to have the capability to model such neural networks on the computer  
 and i 'll show you what that actually looks like so the pixels you can think about as a first layer of neurons and that 's in fact how it works in the eye  that 's the neurons in the retina  
 and those feed forward into one layer after another layer
  after another layer of neurons all connected by synapses of different weights 
 the behavior of this network is characterized by the strengths of all of those synapses those characterize the computational properties of this network  
 and at the end of the day you have a neuron or a small group of neurons that light up saying bird 
 now
 i 'm going to represent those three things the input pixels
 and the
  synapses in the neural network and bird the output
 by three variables  x w and y 
 there are maybe a million or so x 's a million pixels in that image there are billions or trillions of w 's which represent the weights of all these synapses in the neural network 
 and there 's a very small number of y 's of outputs that that network
  is only four letters right 
 so let 's pretend that this is just a simple formula x x w = y i 'm putting the times in scare quotes because what 's really going on there of course is a very complicated series of mathematical operations  
 that 's one equation  there are three variables  
 and we all know that if you have one equation you can solve one variable by knowing the other two things 
 so
 the problem of
  inference that is figuring out that the picture of a bird is a bird is this one it 's where y is the unknown and w and x are known  you know the neural network  you know the pixels
 as you can see that 's actually a relatively straightforward problem you multiply two times three and you 're done i
 'll show you
 an artificial neural network that that we 've built recently
 doing exactly that this is running in real time on a mobile phone
 and that 's  of course  amazing in its own right that mobile phones can do so many billions and trillions of operations per per second
 what you 're looking at is a phone looking at one after another picture of a bird and actually not only saying yes it 's a bird but identifying the species of bird with a network of this sort 
 so in that picture  the x and the w are known  and the y is the
  unknown i 'm glossing over the very difficult part of course which is how on earth do we figure out
 the w the brain that can do such a thing how would we ever learn such a model 
 so this process of learning  of solving for w  if we were doing this with the with the simple equation in which we think about these as numbers we know exactly how to
  divide by two
 and we 're done the problem is with this operator so division we 've used division because it 's the inverse to multiplication but
 as i as i 've just said  the multiplication is a bit of a lie here
 this is a very very complicated very non linear operation it has no inverse so we have to figure out a way to solve the equation
 without a division operator  and the way to do that is fairly straightforward you just say
   let 's play a little algebra trick and move the six over to the right hand side of the equation now we 're still using multiplication  
 and that zero let 's think about it as an error  in other words if we 've solved for w the right way  then the error will be zero  
 and if we haven 't gotten it quite right the error will be greater than zero  
 so now we can just take guesses to minimize the error  and that 's the sort of thing computers are very good at
 you 've taken an initial guess what if w = zero well then the error is six what if w = one the error is four and then the computer can sort of play marco polo  
 and drive down the error close to zero  as it does that it 's getting successive approximations to w
 typically it never quite gets there but after about a dozen steps we 're up to w  = two point nine nine nine which is close enough 
 and this is the learning process
 remember that what 's what 's been going on here is that we 've been taking a lot of known x 's and known y 's and solving for the w in the middle through an iterative process 
 it 's exactly the same way that we do our own learning  we have many many images as babies and we get told this is a bird  this is not a bird 
  so
 now we 've held x and w fixed to solve for y that 's everyday fast perception we figure out how we can solve for w that 's learning which is a lot harder because we need to do error minimization using a lot of training examples 
 and about a year ago alex mordvintsev on our team decided to experiment with what happens if we try solving for
  given a known w and a known y 
 in other words  you know that it 's a bird  and you already have your neural network that you 've trained on on birds  but what is the picture of a bird
 it turns out that by using exactly the same error minimization procedure one can do that with the network trained to recognize birds  
 and the result
 turns out to be 
 a picture of birds
  this is a picture of birds generated entirely by a neural network that was trained to recognize birds  just by solving for x rather than solving for y  and doing that iteratively 
 here 's another fun example this was a work made by mike tyka in our group which
 he calls animal parade it reminds me a little bit of william kentridge 's artworks in which he makes sketches rubs them out makes sketches rubs them out and
  creates a movie this way in this case what mike is doing is varying y over the space of different animals in a network designed to recognize and distinguish different animals from each other and you get this
 strange escher like morph from one animal to another 
 here
  he and alex together have tried reducing
  the y 's to a space of only two dimensions thereby making a map
 out of the space of all things recognized by this network
 doing this kind of synthesis or generation of imagery over that entire surface varying y over the surface you make a kind of map a visual map of all the things the network
 knows how to recognize the animals are all here armadillo is right in that spot  you can do this with other kinds of networks as well this is
 a network designed to recognize faces to distinguish one face from another
 and here we 're putting in a y that says me my own face parameters  and when this thing solves for x it generates this rather crazy kind of cubist  surreal  
 psychedelic picture of me from multiple points of view at once the reason it looks like multiple points of view at once is because
 that network is designed to get rid of the ambiguity of a face being in one pose or another pose
  being looked at with one kind of lighting another kind of lighting so when you do this sort of reconstruction if you don 't use some sort of guide image or guide statistics then you 'll get a sort of confusion of different points of view 
 because it 's ambiguous  
 this is what happens if alex uses his own face as a guide image during that optimization process to reconstruct my own face  
 so you can see it 's not
 perfect there 's still quite a lot of work to do on how we optimize that optimization process  
 but you start to get something more like a coherent face rendered using my own face as a guide 
 you don 't have to start with
 a blank canvas or with white noise when you 're solving for x you can begin with an x that is itself already some other image 
  that 's what this little demonstration is this is a network
 that
 that is designed to categorize all sorts of different objects man made structures animals here we 're starting with just a picture of clouds  
 and as we optimize basically this network is figuring out what it sees in the clouds  
 and the more time you spend looking at this the more things you also will see in the clouds  
 you could also use the face network to hallucinate into this and you get some pretty crazy stuff
 or mike has done some other experiments in which he takes
 that cloud image hallucinates zooms hallucinates zooms hallucinates zooms and in this way  you can get a sort of
 fugue state of the network i suppose or a sort of
 free
  in which the network is eating its own tail so every every image is now the basis for what do i think i see next what do i think i see next what do i think i see next 
 i showed this for the first time
 in public to
 to a group
 at a lecture in seattle called higher education this was right after marijuana was legalized 
  like to finish up quickly by just noting that this technology is not
 constrained i 've shown you purely visual examples because they 're really fun to look at it 's not a purely visual technology 
 our artist collaborator ross goodwin has done experiments involving a camera that takes a picture  and then a computer in his backpack writes a poem using neural networks based on the contents
  of the image  and that poetry neural network has been trained on
 a large corpus of 20th century poetry and the poetry is you know i think kind of not bad actually in closing  i think that
 per michelangelo i think he was right perception and creativity are very intimately connected 
 what we 've just seen are neural networks that are entirely trained to discriminate or to recognize different things in the world 
 able to be run in reverse to generate
  one of the things that suggests to me is not only that michelangelo really did see the sculpture in the blocks of stone but that
 any any creature any being any alien that is able to do perceptual acts of that sort is also able to create because it 's exactly the same machinery that 's used in both cases 
 also i think that
 perception and creativity are by no means uniquely human  we start to
  have computer models that can do exactly these sorts of things and that ought to be unsurprising the brain is computational 
 and finally 
 computing began as an exercise in designing intelligent machinery  it was very much modeled after the idea of how could we make machines intelligent 
 and we finally are starting to fulfill
  some of the promises of those early pioneers of turing and von neumann and mcculloch and pitts  and
 i think that computing is not just about accounting or playing candy crush or something from the beginning we modeled them after our minds 
 and they give us both the ability to understand our own minds better and to extend them  
 thank you very much
