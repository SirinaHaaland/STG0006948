  i work with a bunch of mathematicians philosophers and computer scientists and
 we sit around and think
 about the future of machine intelligence among other things some people think that some of these things are sort of science fiction y far out there
  crazy  but i like to say  okay  let 's look at the modern human condition 
 laughter this is the normal way for things to be but
 if we think about it we are actually recently arrived guests on this planet the human species
  be ten minutes old the industrial era started two seconds ago  
 another way to look at this is to think of world gdp over the last ten thousand years i 've actually taken the trouble to plot this for you in a graph 
 it looks like this it
 's a curious shape for a normal condition  i sure wouldn 't want to sit on it
  ask ourselves what is the cause of this current anomaly some people would say it 's technology  now it 's true
  technology has accumulated through human history
  and right now  technology advances extremely rapidly
 that is the proximate cause that 's why we are currently so very productive  but i like to think back further
 to the ultimate cause
  look at these two highly distinguished gentlemen  
 we have kanzi he 's mastered two hundred lexical tokens 
 an incredible feat  and ed witten unleashed the second superstring revolution 
 if we look under the hood this is what we find basically the same thing one is a little larger  it maybe also
  a few tricks in the exact way it 's wired these invisible differences cannot be too complicated however because there have only been two hundred and fifty thousand
 generations since our last common ancestor we know that complicated mechanisms take a long time to evolve so
 a bunch of relatively minor changes take us from kanzi to witten from broken off tree branches to intercontinental ballistic missiles  
 so this then seems pretty obvious that
  everything we 've achieved and everything we care about depends crucially
 on some relatively minor changes that made the human mind  and the corollary of course is that
 any further changes that could significantly change the substrate of thinking could have potentially enormous consequences 
 some of my colleagues think we 're on the verge of something that could
 cause a profound change in that substrate and that is machine 
 artificial intelligence used to be about putting commands in a box you would have human programmers that would painstakingly handcraft knowledge items 
 you build up these expert systems and they were kind of useful for some purposes
 but they were very brittle you couldn 't scale them  basically you got out only what you put in but
 since then a paradigm shift has taken place in the field of artificial intelligence today the action is really around machine learning  so rather than 
 knowledge representations and and features  
 we create algorithms that learn often from raw perceptual data  basically the same thing that the human infant does
 the result is a i that is not limited to one domain the same system can learn to translate between any pairs of languages  
 or learn to play any
 computer game on the atari console now of course a i is still nowhere near having the same powerful
  ability to learn and plan as a human being has the cortex still has some algorithmic tricks that we don 't yet know how to match in machines 
 so the question is how far are we from being able to match those tricks 
 a couple of years ago we did a survey of some of the world 's leading a i experts to see what they think and one of the questions we asked was 
 by which year do you think there is a fifty percent probability that we will have achieved
 we defined human level here as the ability to perform
 almost any job at least as well as an adult human so real human level not just within some limited domain and the median answer was
 two thousand and forty or two thousand and fifty depending on precisely which group of experts we asked  
 now it could happen much much later or sooner the truth is nobody really knows
  what we do know is that the ultimate limit to information processing in a machine substrate lies far outside the limits in biological tissue 
 this comes down to physics 
 a biological neuron fires maybe at two hundred hertz two hundred times a second  but even a present day transistor operates at the gigahertz
  propagate slowly in axons one hundred meters per second  tops but in computers signals can travel at the speed of light there are also
 size limitations like a human brain has to fit inside a cranium but a computer can be the size of a warehouse or larger  
 so the potential for 
  lies dormant in matter much like the power of the atom lay dormant throughout human history
  patiently waiting there until one thousand nine hundred and forty five in this century scientists may learn to
 awaken the power of artificial intelligence  and i think we might then see
 an intelligence explosion now most people when they think about
 what is smart and what is dumb  i think have in mind a picture roughly like this  so at one end we have the village idiot
  then far over at the other side we have ed witten or albert einstein or whoever your favorite guru is  but
 i think that from the point of view of artificial intelligence the
 true picture is actually probably more like this 
 ai starts out at this point here at zero intelligence and then  after many many years of really hard work maybe eventually we get to
  artificial intelligence something that can navigate cluttered
 environments as well as a mouse can and then  after many many more years of really hard work lots of investment maybe eventually we get to
 artificial intelligence  
 and then  after even more years of really really hard work  we get to village idiot artificial intelligence  
 and a few moments later  we are beyond ed witten  
 the train doesn 't stop at
  station  it 's likely rather to swoosh right by 
 now this has profound implications  particularly when it comes to questions of power 
 for example  chimpanzees are strong pound for pound a chimpanzee is about twice as strong as a fit human male  
 and yet  the fate of kanzi and his
  depends a lot more on what we humans do than on what the chimpanzees do themselves 
 once there is superintelligence the fate of humanity may depend on what the 
 think about it 
 machine intelligence is the last invention that humanity will ever need to make machines will then be better at inventing than we are and they 'll be doing so on digital timescales
  what this means is basically
 a telescoping of the future think of all the crazy
 technologies that you could have imagined maybe humans could have developed in the fullness of time cures for aging  space colonization
 nanobots or uploading of minds into computers all kinds of science fiction y stuff that 's nevertheless consistent with the laws of physics all of this
  could develop and possibly quite rapidly  now a superintelligence with such technological maturity
 would be extremely powerful 
 and at least in some scenarios  it would be able to get what it wants we
 would then have a future that would be shaped by the preferences of this a i 
 now a good question is what are those preferences
  here it gets trickier to make any headway with this we must first of all avoid anthropomorphizing and
 this is ironic because every newspaper article about the future of a i has a picture of this 
 so i think what we need to do is to conceive of the issue more abstractly  not in terms of vivid hollywood scenarios  we need to think of intelligence
 as an optimization process a process that steers the future
  into a particular set of configurations a superintelligence is a really strong optimization process it 's extremely good at using available means
 to achieve a state in which its goal is realized 
 this means that there is no necessary connection between being highly intelligent in this sense 
 and having an objective that we humans would find worthwhile or meaningful  
 suppose we give an
  the goal to make humans smile 
 when the a i is weak it performs useful or amusing actions that cause its user to smile  
 when the a i becomes superintelligent it realizes that there is a more effective way to achieve this goal take control of the world
 and stick electrodes into the facial muscles of humans to
  another example suppose we give a i the goal to solve a difficult mathematical problem 
 when the a i becomes superintelligent it realizes that the most effective way to get the solution to this problem
 is by transforming the planet into a giant computer so as to increase its thinking capacity  
 and notice that this gives the a i s an instrumental reason to do things to us that we might not approve of human beings in this model are threats we could prevent the mathematical problem from being solved
 perceivably things won 't go wrong in these particular ways these are cartoon examples  
 but the general point here is important if you create a really powerful optimization process to maximize for objective x you better make sure that your definition of x incorporates everything you care about
 this is a lesson that 's also taught in many a myth
  king midas
 wishes that everything he touches be turned into gold  
 he touches his daughter  she turns into gold he touches his food it turns into gold this could become practically relevant  
 not just as a metaphor for greed  but as an illustration of what happens if you create a powerful optimization process and give it
 misconceived or poorly specified goals 
  if a computer starts sticking electrodes into people 's faces we 'd just shut it off a this is not necessarily so easy to do if we 've
 grown dependent on the system like where is the off switch to the internet 
 why haven 't the chimpanzees flicked the off switch to humanity  
 or the neanderthals they certainly had reasons  we have an off switch for example right here
 choking the reason is that we are an intelligent adversary we can anticipate threats and plan around them  but so could a superintelligent agent and
 it would be much better at that than we are the point is we should not be confident
 that we have this under control here and we could try to make our job a little bit easier by say putting the a i in a box
  like a secure software environment a virtual reality simulation from which it cannot escape  but how confident can we be that
 the  a i couldn 't find a bug given that merely human hackers find bugs all the time i 'd say probably not very confident
 so we disconnect the ethernet cable to create an air gap  but again like merely human hackers routinely transgress air gaps
  using social engineering right now as i speak  i 'm sure there is some employee out there somewhere who has been talked into handing out her account details by somebody claiming to be from the i t department
  more creative scenarios are also possible like if you 're the a i you can
 imagine wiggling electrodes around in your internal circuitry to create radio waves that you can use to communicate or maybe you could pretend to malfunction  and then
 when the programmers open you up to see what went wrong with you they look at the source code bam the manipulation can take place 
 or it could output the blueprint to a really nifty technology and when we implement it  it has some surreptitious side effect that the  a i 
 had planned  
 the point here is that we should not be confident in our ability to keep a superintelligent genie locked up in its bottle forever sooner or later
  will out i believe that
 the answer here is to figure out how to create superintelligent a i such that even if when it escapes 
 it is still safe because it is fundamentally on our side because it shares our values i see no way around this difficult problem 
 now i 'm actually fairly optimistic that this problem can be solved we wouldn 't have to
  down a long list of everything we care about or worse yet  
 spell it out in some computer language like c + + or python that would be a task beyond hopeless  instead  we would create an a i 
 that uses its intelligence to learn what we value  
 and its motivation system is constructed in such a way
 that it is motivated to pursue our values or to perform actions that
  it predicts we would approve of we would thus leverage its intelligence as much as possible to solve the problem of value loading 
 this can happen  and the outcome could be very good for humanity  but it doesn 't
 happen
 automatically  the initial conditions for the intelligence explosion might need to be set up in just the right way if we are to
  have a controlled detonation  the values that the a i has need to match ours not just in the
 familiar context like where we can easily check how the a i behaves but also in all novel contexts that the  a i might encounter in the indefinite future and there are also some
 esoteric issues that would need to be solved  sorted out the exact details of its decision theory how to deal with logical uncertainty and so forth
  so the technical problems that need to be solved to make this work look quite difficult not as difficult as making a 
 but fairly difficult 
 here is the worry making superintelligent a i is a really hard challenge  making 
 that is safe involves some additional challenge on top of that the risk is that if somebody figures out
  to crack the first challenge without also having cracked the additional challenge of ensuring perfect safety  so i think that
 we should work out a solution to the control problem in advance so that we have it available by the time it is needed  
 now it might be that we cannot solve the entire control problem in advance because maybe some elements
 can only be put in place once you know the details of
  the architecture where it will be implemented  but the more of the control problem
 that we solve in advance  the better the odds that the transition to the machine intelligence era will go well
  this to me looks like a thing that is well worth doing
 and i can imagine that if
 things turn out okay  that
 people a million years from now look back at this century and it might well be that
 they say that the one thing we did that really mattered was to get this thing right thank
